[{"title":"JVM垃圾回收机制","date":"2018-10-18T04:08:42.000Z","path":"2018/10/18/JVM垃圾回收机制/","text":"浅谈JVM垃圾回收 什么是垃圾回收（Garbage Collection，GC）​ 垃圾回收机制：在系统运行过程中，会产生一些无用的对象，这些对象占据着一定的内存，如果不对这些对象清理回收无用对象的内存，可能会导致内存的耗尽，所以垃圾回收机制回收的是内存。同时GC回收的是堆区和方法区的内存。 哪些内存需要回收JVM的内存结构包括五大区域：程序计数器、虚拟机栈、本地方法栈、堆区、方法区。其中程序计数器、虚拟机栈、本地方法栈3个区域随线程而生、随线程而灭，因此这几个区域的内存分配和回收都具备确定性，就不需要过多考虑回收的问题，因为方法结束或者线程结束时，内存自然就跟随着回收了。而Java堆区和方法区则不一样、不一样!(怎么不一样说的朗朗上口)，这部分内存的分配和回收是动态的，正是垃圾收集器所需关注的部分。 垃圾收集器在对堆区和方法区进行回收前，首先要确定这些区域的对象哪些可以被回收，哪些暂时还不能回收，这就要用到判断对象是否存活的算法！（面试官肯定没少问你吧） 引用计数算法算法分析： 引用计数是垃圾收集器中的早期策略。在这种方法中，堆中每个对象实例都有一个引用计数。当一个对象被创建时，就将该对象实例分配给一个变量，该变量计数设置为1。当任何其它变量被赋值为这个对象的引用时，计数加1（a = b,则b引用的对象实例的计数器+1），但当一个对象实例的某个引用超过了生命周期或者被设置为一个新值时，对象实例的引用计数器减1。任何引用计数器为0的对象实例可以被当作垃圾收集。当一个对象实例被垃圾收集时，它引用的任何对象实例的引用计数器减1。 优缺点：优点：引用计数收集器可以很快的执行，交织在程序运行中。对程序需要不被长时间打断的实时环境比较有利。缺点：无法检测出循环引用。如父对象有一个对子对象的引用，子对象反过来引用父对象。这样，他们的引用计数永远不可能为0。 123456789101112131415public class ReferenceFindTest &#123; public static void main(String[] args) &#123; MyObject object1 = new MyObject(); MyObject object2 = new MyObject(); object1.object = object2; object2.object = object1; object1 = null; object2 = null; &#125;&#125;/**这段代码是用来验证引用计数算法不能检测出循环引用。最后面两句将object1和object2赋值为null，也就是说object1和object2指向的对象已经不可能再被访问，但是由于它们互相引用对方，导致它们的引用计数器都不为0，那么垃圾收集器就永远不会回收它们。*/ 可达性分析算法可达性分析算法是从离散数学中的图论引入的，程序把所有的引用关系看作一张图，从一个节点GC ROOT开始，寻找对应的引用节点，找到这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的节点则被认为是没有被引用到的节点，即无用的节点，无用的节点将会被判定为是可回收的对象。 上图红色为无用的节点，可以被回收。 目前Java中可以作为GC ROOT的对象有：1、虚拟机栈中引用的对象（栈帧中的本地变量表）2、方法区中类静态属性引用的对象3、 方法区中常量引用的对象4、本地方法栈中JNI（Native方法）引用的对象基本所有GC算法都引用根搜索算法这种概念。 Java中的引用你了解多少 无论是通过引用计数算法判断对象的引用数量，还是通过可达性分析算法判断对象的引用链是否可达，判定对象是否存活都与“引用”有关。在Java语言中，将引用又分为强引用、软引用、弱引用、虚引用4种，这四种引用强度依次逐渐减弱。 强引用 在程序代码中普遍存在的，类似 Object obj = new Object() 这类引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象。 软引用 用来描述一些还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收后还没有足够的内存，才会抛出内存溢出异常。 弱引用 也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象。 虚引用 也叫幽灵引用或幻影引用（名字真会取，很魔幻的样子），是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。它的作用是能在这个对象被收集器回收时收到一个系统通知。 不要被概念吓到，也别担心，还没跑题，再深入，可就不好说了。罗列这四个概念的目的是为了说明，无论引用计数算法还是可达性分析算法都是基于强引用而言的。 对象死亡（被回收）前的最后一次挣扎 即使在可达性分析算法中不可达的对象，也并非是“非死不可”，这时候它们暂时处于“缓刑”阶段，要真正宣告一个对象死亡，至少要经历两次标记过程。 第一次标记：如果对象在进行可达性分析后发现没有与GC Roots相连接的引用链，那它将会被第一次标记； 第二次标记：第一次标记后接着会进行一次筛选，筛选的条件是此对象是否有必要执行finalize()方法。在finalize()方法中没有重新与引用链建立关联关系的，将被进行第二次标记。 第二次标记成功的对象将真的会被回收，如果对象在finalize()方法中重新与引用链建立了关联关系，那么将会逃离本次回收，继续存活。猿们还跟的上吧，嘿嘿。 方法区如何判断是否需要回收 方法区存储内容是否需要回收的判断可就不一样咯。方法区主要回收的内容有：废弃常量和无用的类。对于废弃常量也可通过引用的可达性来判断，但是对于无用的类则需要同时满足下面3个条件： 该类所有的实例都已经被回收，也就是Java堆中不存在该类的任何实例； 加载该类的ClassLoader已经被回收； 该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。 常用的垃圾收集算法标记-清除算法 标记-清除算法采用从根集合（GC Roots）进行扫描，对存活的对象进行标记，标记完毕后，再扫描整个空间中未被标记的对象，进行回收，如下图所示。 标记-清除算法不需要进行对象的移动，只需对不存活的对象进行处理，在存活对象比较多的情况下极为高效，但由于标记-清除算法直接回收不存活的对象，因此会造成内存碎片。 复制算法 复制算法将内存划分为两个区间，使用此算法时，所有动态分配的对象都只能分配在其中一个区间（活动区间），而另外一个区间（空间区间）则是空闲的。 复制算法采用从根集合扫描，将存活的对象复制到空闲区间，当扫描完毕活动区间后，会的将活动区间一次性全部回收。此时原本的空闲区间变成了活动区间。下次GC时候又会重复刚才的操作，以此循环。 复制算法在存活对象比较少的时候，极为高效，但是带来的成本是牺牲一半的内存空间用于进行对象的移动。所以复制算法的使用场景，必须是对象的存活率非常低才行，而且最重要的是，我们需要克服50%内存的浪费。 标记-整理算法 标记-整理算法采用 标记-清除 算法一样的方式进行对象的标记、清除，但在回收不存活的对象占用的空间后，会将所有存活的对象往左端空闲空间移动，并更新对应的指针。标记-整理 算法是在标记-清除 算法之上，又进行了对象的移动排序整理，因此成本更高，但却解决了内存碎片的问题。 JVM为了优化内存的回收，使用了分代回收的方式，对于新生代内存的回收（Minor GC）主要采用复制算法。而对于老年代的回收（Major GC），大多采用标记-整理算法。 分代收集算法 分代收集算法是目前大部分JVM的垃圾收集器采用的算法。它的核心思想是根据对象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代（Tenured Generation）和新生代（Young Generation），在堆区之外还有一个代就是永久代（Permanet Generation）。老年代的特点是每次垃圾收集时只有少量对象需要被回收，而新生代的特点是每次垃圾回收时都有大量的对象需要被回收，那么就可以根据不同代的特点采取最适合的收集算法。 年轻代（Young Generation）的回收算法a) 所有新生成的对象首先都是放在年轻代的。年轻代的目标就是尽可能快速的收集掉那些生命周期短的对象。 b) 新生代内存按照8:1:1的比例分为一个eden区和两个survivor(survivor0,survivor1)区。一个Eden区，两个 Survivor区(一般而言)。大部分对象在Eden区中生成。回收时先将eden区存活对象复制到一个survivor0区，然后清空eden区，当这个survivor0区也存放满了时，则将eden区和survivor0区存活对象复制到另一个survivor1区，然后清空eden和这个survivor0区，此时survivor0区是空的，然后将survivor0区和survivor1区交换，即保持survivor1区为空， 如此往复。 c) 当survivor1区不足以存放 eden和survivor0的存活对象时，就将存活对象直接存放到老年代。若是老年代也满了就会触发一次Full GC，也就是新生代、老年代都进行回收。 d) 新生代发生的GC也叫做Minor GC，MinorGC发生频率比较高(不一定等Eden区满了才触发)。 年老代（Old Generation）的回收算法a) 在年轻代中经历了N次垃圾回收后仍然存活的对象，就会被放到年老代中。因此，可以认为年老代中存放的都是一些生命周期较长的对象。 b) 内存比新生代也大很多(大概比例是1:2)，当老年代内存满时触发Major GC即Full GC，Full GC发生频率比较低，老年代对象存活时间比较长，存活率标记高。 持久代（Permanent Generation）的回收算法 用于存放静态文件，如Java类、方法等。持久代对垃圾回收没有显著影响，但是有些应用可能动态生成或者调用一些class，例如Hibernate 等，在这种时候需要设置一个比较大的持久代空间来存放这些运行过程中新增的类。持久代也称方法区，具体的回收可参见上文2.5节。 常见的垃圾收集器下面一张图是HotSpot虚拟机包含的所有收集器 Serial收集器（复制算法)新生代单线程收集器，标记和清理都是单线程，优点是简单高效。是client级别默认的GC方式，可以通过-XX:+UseSerialGC来强制指定。 Serial Old收集器(标记-整理算法)老年代单线程收集器，Serial收集器的老年代版本。 ParNew收集器(停止-复制算法) 新生代收集器，可以认为是Serial收集器的多线程版本,在多核CPU环境下有着比Serial更好的表现。 Parallel Scavenge收集器(停止-复制算法)并行收集器，追求高吞吐量，高效利用CPU。吞吐量一般为99%， 吞吐量= 用户线程时间/(用户线程时间+GC线程时间)。适合后台应用等对交互相应要求不高的场景。是server级别默认采用的GC方式，可用-XX:+UseParallelGC来强制指定，用-XX:ParallelGCThreads=4来指定线程数。 Parallel Old收集器(停止-复制算法)Parallel Scavenge收集器的老年代版本，并行收集器，吞吐量优先。 CMS(Concurrent Mark Sweep)收集器（标记-清理算法）高并发、低停顿，追求最短GC回收停顿时间，cpu占用比较高，响应时间快，停顿时间短，多核cpu 追求高响应时间的选择。 GC是什么时候触发的新生代 GC（Minor GC）：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，所以 Minor GC 非常频繁，一般回收速度也比较快。 老年代 GC（Major GC / Full GC）：指发生在老年代的 GC，出现了 Major GC，经常会伴随至少一次的 Minor GC（但非绝对的，在 ParallelScavenge 收集器的收集策略里就有直接进行 Major GC 的策略选择过程） 。MajorGC 的速度一般会比 Minor GC 慢 10倍以上。 Minor GC触发机制：当年轻代满时就会触发Minor GC，这里的年轻代满指的是Eden代满，Survivor满不会引发GC Full GC触发机制：对整个堆进行整理，包括Young、Tenured和Perm。Full GC因为需要对整个堆进行回收，所以比较慢，因此应该尽可能减少Full GC的次数。在对JVM调优的过程中，很大一部分工作就是对于Full GC的调节。有如下原因可能导致Full GC：a) 年老代（Tenured）被写满；b) 持久代（Perm）被写满；c) System.gc()被显示调用；d) 上一次GC之后Heap的各域分配策略动态变化； 其中Minor GC如下图所示 ​ 虚拟机给每个对象定义了一个对象年龄（Age）计数器。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1。对象在 Survivor 区中每熬过一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁）时，就会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold (阈值)来设置。 减少GC开销的措施 根据上述GC的机制,程序的运行会直接影响系统环境的变化,从而影响GC的触发。若不针对GC的特点进行设计和编码,就会出现内存驻留等一系列负面影响。为了避免这些影响,基本的原则就是尽可能地减少垃圾和减少GC过程中的开销。具体措施包括以下几个方面: (1)不要显式调用System.gc() 此函数建议JVM进行主GC,虽然只是建议而非一定,但很多情况下它会触发主GC,从而增加主GC的频率,也即增加了间歇性停顿的次数。 (2)尽量减少临时对象的使用 临时对象在跳出函数调用后,会成为垃圾,少用临时变量就相当于减少了垃圾的产生,从而延长了出现上述第二个触发条件出现的时间,减少了主GC的机会。 (3)对象不用时最好显式置为Null 一般而言,为Null的对象都会被作为垃圾处理,所以将不用的对象显式地设为Null,有利于GC收集器判定垃圾,从而提高了GC的效率。 (4)尽量使用StringBuffer,而不用String来累加字符串 由于String是固定长的字符串对象,累加String对象时,并非在一个String对象中扩增,而是重新创建新的String对象,如Str5=Str1+Str2+Str3+Str4,这条语句执行过程中会产生多个垃圾对象,因为对次作“+”操作时都必须创建新的String对象,但这些过渡对象对系统来说是没有实际意义的,只会增加更多的垃圾。避免这种情况可以改用StringBuffer来累加字符串,因StringBuffer是可变长的,它在原有基础上进行扩增,不会产生中间对象。 (5)能用基本类型如Int,Long,就不用Integer,Long对象 基本类型变量占用的内存资源比相应对象占用的少得多,如果没有必要,最好使用基本变量。 (6)尽量少用静态对象变量 静态变量属于全局变量,不会被GC回收,它们会一直占用内存。 (7)分散对象创建或删除的时间 集中在短时间内大量创建新对象,特别是大对象,会导致突然需要大量内存,JVM在面临这种情况时,只能进行主GC,以回收内存或整合内存碎片,从而增加主GC的频率。集中删除对象,道理也是一样的。它使得突然出现了大量的垃圾对象,空闲空间必然减少,从而大大增加了下一次创建新对象时强制主GC的机会。 GC相关的JVM参数伊甸园（Eden）：这是对象最初诞生的区域，并且对大多数对象来说，这里是它们唯一存在过的区域。 幸存者乐园（Survivor）：从伊甸园幸存下来的对象会被挪到这里。 终身颐养园（Tenured）：这是足够老的幸存对象的归宿。年轻代收集（Minor-GC）过程是不会触及这个地方的。当年轻代收集不能把对象放进终身颐养园时，就会触发一次完全收集（Major-GC），这里可能还会牵扯到压缩，以便为大对象腾出足够的空间。与垃圾回收相关的JVM参数： -Xms / -Xmx — 堆的初始大小 / 堆的最大大小 -Xmn — 堆中年轻代的大小 -XX:-DisableExplicitGC — 让System.gc()不产生任何作用 -XX:+PrintGCDetail — 打印GC的细节-XX:+PrintGCDateStamps — 打印GC操作的时间戳 关于垃圾回收的几点补充经过上述的说明，可以发现垃圾回收有以下的几个特点：（1）垃圾收集发生的不可预知性：由于实现了不同的垃圾回收算法和采用了不同的收集机制，所以它有可能是定时发生，有可能是当出现系统空闲CPU资源时发生，也有可能是和原始的垃圾收集一样，等到内存消耗出现极限时发生，这与垃圾收集器的选择和具体的设置都有关系。 （2）垃圾收集的精确性：主要包括2 个方面： ​ （a）垃圾收集器能够精确标记活着的对象； ​ （b）垃圾收集器能够精确地定位对象之间的引用关系。前者是完全地回收所有废弃对象的前提，否则就可能造成内存泄漏。而后者则是实现归并和复制等算法的必要条件。所有不可达对象都能够可靠地得到回收，所有对象都能够重新分配，允许对象的复制和对象内存的缩并，这样就有效地防止内存的支离破碎。 （3）现在有许多种不同的垃圾收集器，每种有其算法且其表现各异，既有当垃圾收集开始时就停止应用程序的运行，又有当垃圾收集开始时也允许应用程序的线程运行，还有在同一时间垃圾收集多线程运行。 （4）垃圾收集的实现和具体的JVM 以及JVM的内存模型有非常紧密的关系。不同的JVM 可能采用不同的垃圾收集，而JVM 的内存模型决定着该JVM可以采用哪些类型垃圾收集。现在，HotSpot 系列JVM中的内存系统都采用先进的面向对象的框架设计，这使得该系列JVM都可以采用最先进的垃圾收集。 （5）随着技术的发展，现代垃圾收集技术提供许多可选的垃圾收集器，而且在配置每种收集器的时候又可以设置不同的参数，这就使得根据不同的应用环境获得最优的应用性能成为可能。 针对以上特点，我们在使用的时候要注意： （1）不要试图去假定垃圾收集发生的时间，这一切都是未知的。比如，方法中的一个临时对象在方法调用完毕后就变成了无用对象，这个时候它的内存就可以被释放。 （2）Java中提供了一些和垃圾收集打交道的类，而且提供了一种强行执行垃圾收集的方法–调用System.gc()，但这同样是个不确定的方法。Java 中并不保证每次调用该方法就一定能够启动垃圾收集，它只不过会向JVM发出这样一个申请，到底是否真正执行垃圾收集，一切都是个未知数。 （3）挑选适合自己的垃圾收集器。一般来说，如果系统没有特殊和苛刻的性能要求，可以采用JVM的缺省选项。否则可以考虑使用有针对性的垃圾收集器，比如增量收集器就比较适合实时性要求较高的系统之中。系统具有较高的配置，有比较多的闲置资源，可以考虑使用并行标记/清除收集器。 （4）关键的也是难把握的问题是内存泄漏。良好的编程习惯和严谨的编程态度永远是最重要的，不要让自己的一个小错误导致内存出现大漏洞。 （5）尽早释放无用对象的引用。大多数程序员在使用临时变量的时候，都是让引用变量在退出活动域(scope)后，自动设置为null，暗示垃圾收集器来收集该对象，还必须注意该引用的对象是否被监听，如果有，则要去掉监听器，然后再赋空值。","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://imnice.github.io/tags/Java基础/"}]},{"title":"二叉堆&堆排序","date":"2018-10-17T04:08:42.000Z","path":"2018/10/17/二叉堆&堆排序/","text":"二叉堆&amp;堆排序 什么是二叉堆？二叉堆本质上是一种完全二叉树，它分为两个类型：1.最大堆（max heap，又称大顶堆、大根堆）2.最小堆（min heap，又称小顶堆、小根堆） 最大堆就是任何一个父节点的值，都大于等于它左右孩子节点的值。同理，最小堆就是任何一个父节点的值，都小于等于它左右孩子节点的值。 如何构建一个堆构建堆主要依靠堆得自我调整 堆的自我调整对于二叉堆，如下有几种操作：插入节点删除节点构建二叉堆 这几种操作都是基于堆的自我调整。 下面让我们以最小堆为例，看一看二叉堆是如何进行自我调整的。 插入节点二叉堆的节点插入，插入位置是完全二叉树的最后一个位置。比如我们插入一个新节点，值是 0。 这时候，我们让节点0的它的父节点5做比较，如果0小于5，则让新节点“上浮”，和父节点交换位置。 继续用节点0和父节点3做比较，如果0小于3，则让新节点继续“上浮”。 继续比较，最终让新节点0上浮到了堆顶位置。 删除节点二叉堆的节点删除过程和插入过程正好相反，所删除的是处于堆顶的节点。比如我们删除最小堆的堆顶节点1。 这时候，为了维持完全二叉树的结构，我们把堆的最后一个节点10补到原本堆顶的位置。 接下来我们让移动到堆顶的节点10和它的左右孩子进行比较，如果左右孩子中最小的一个（显然是节点2）比节点10小，那么让节点10“下沉”。 继续让节点10和它的左右孩子做比较，左右孩子中最小的是节点7，由于10大于7，让节点10继续“下沉”。 这样一来，二叉堆重新得到了调整。 构建二叉堆构建二叉堆，也就是把一个无序的完全二叉树调整为二叉堆，本质上就是让所有非叶子节点依次下沉。 我们举一个无序完全二叉树的例子： 首先，我们从最后一个非叶子节点开始，也就是从节点10开始。如果节点10大于它左右孩子中最小的一个，则节点10下沉。 接下来轮到节点3，如果节点3大于它左右孩子中最小的一个，则节点3下沉。 接下来轮到节点1，如果节点1大于它左右孩子中最小的一个，则节点1下沉。事实上节点1小于它的左右孩子，所以不用改变。 接下来轮到节点7，如果节点7大于它左右孩子中最小的一个，则节点7下沉。 节点7继续比较，继续下沉。 这样一来，一颗无序的完全二叉树就构建成了一个最小堆。 堆的代码实现在撸代码之前，我们还需要明确一点： 二叉堆虽然是一颗完全二叉树，但它的存储方式并不是链式存储，而是顺序存储。换句话说，二叉堆的所有节点都存储在数组当中。 数组中，在没有左右指针的情况下，如何定位到一个父节点的左孩子和右孩子呢？ 像图中那样，我们可以依靠数组下标来计算。 假设父节点的下标是parent，那么它的左孩子下标就是 2*parent+1；它的右孩子下标就是 2*parent+2 。 比如上面例子中，节点6包含9和10两个孩子，节点6在数组中的下标是3，节点9在数组中的下标是7，节点10在数组中的下标是8。 7 = 3*2+1 8 = 3*2+2 刚好符合规律。 有了这个前提，下面的代码就更好理解了： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import java.util.Arrays;public class HeapOperator &#123; /** * * 上浮调整 * * @param array * 待调整的堆 * */ public static void upAdjust(int[] array) &#123; int childIndex = array.length - 1; int parentIndex = (childIndex - 1) / 2; // temp保存插入的叶子节点值，用于最后的赋值 int temp = array[childIndex]; while (childIndex &gt; 0 &amp;&amp; temp &lt; array[parentIndex]) &#123; // 无需真正交换，单向赋值即可 array[childIndex] = array[parentIndex]; childIndex = parentIndex; parentIndex = (parentIndex - 1) / 2; &#125; array[childIndex] = temp; &#125; /** * * 下沉调整 * * @param array * 待调整的堆 * * @param parentIndex * 要下沉的父节点 * * @param parentIndex * 堆的有效大小 * */ public static void downAdjust(int[] array, int parentIndex, int length) &#123; // temp保存父节点值，用于最后的赋值 int temp = array[parentIndex]; int childIndex = 2 * parentIndex + 1; while (childIndex &lt; length) &#123; // 如果有右孩子，且右孩子小于左孩子的值，则定位到右孩子 if (childIndex + 1 &lt; length &amp;&amp; array[childIndex + 1] &lt; array[childIndex]) &#123; childIndex++; &#125; // 如果父节点小于任何一个孩子的值，直接跳出 if (temp &lt;= array[childIndex]) break; // 无需真正交换，单向赋值即可 array[parentIndex] = array[childIndex]; parentIndex = childIndex; childIndex = 2 * childIndex + 1; &#125; array[parentIndex] = temp; &#125; /** * * 构建堆 * * @param array * 待调整的堆 * */ public static void buildHeap(int[] array) &#123; // 从最后一个非叶子节点开始，依次下沉调整 for (int i = array.length / 2; i &gt;= 0; i--) &#123; downAdjust(array, i, array.length - 1); &#125; &#125; public static void main(String[] args) &#123; int[] array = new int[] &#123; 1, 3, 2, 6, 5, 7, 8, 9, 10, 0 &#125;; upAdjust(array); System.out.println(Arrays.toString(array)); // [0, 1, 2, 6, 3, 7, 8, 9, 10, 5] array = new int[] &#123; 7, 1, 3, 10, 5, 2, 8, 9, 6 &#125;; buildHeap(array); System.out.println(Arrays.toString(array)); // [1, 5, 2, 9, 7, 3, 8, 10, 6] &#125;&#125; 代码中有一个优化的点，就是父节点和孩子节点做连续交换时，并不一定要真的交换，只需要先把交换一方的值存入temp变量，做单向覆盖，循环结束后，再把temp的值存入交换后的最终位置。 堆排序让我们回顾一下二叉堆和最大堆的特性： 1.二叉堆本质上是一种完全二叉树 2.最大堆的堆顶是整个堆中的最大元素 当我们删除一个最大堆的堆顶（并不是完全删除，而是替换到最后面），经过自我调节，第二大的元素就会被交换上来，成为最大堆的新堆顶。 正如上图所示，当我们删除值为10的堆顶节点，经过调节，值为9的新节点就会顶替上来；当我们删除值为9的堆顶节点，经过调节，值为8的新节点就会顶替上来……. 由于二叉堆的这个特性，我们每一次删除旧堆顶，调整后的新堆顶都是大小仅次于旧堆顶的节点。那么我们只要反复删除堆顶，反复调节二叉堆，所得到的集合就成为了一个有序集合，过程如下： 删除节点9，节点8成为新堆顶： 删除节点8，节点7成为新堆顶： 删除节点7，节点6成为新堆顶：删除节点6，节点5成为新堆顶：删除节点5，节点4成为新堆顶：删除节点4，节点3成为新堆顶：删除节点3，节点2成为新堆顶：到此为止，我们原本的最大堆已经变成了一个从小到大的有序集合。之前说过二叉堆实际存储在数组当中，数组中的元素排列如下：由此，我们可以归纳出堆排序算法的步骤：1. 把无序数组构建成二叉堆。2. 循环删除堆顶元素，移到集合尾部，调节堆产生新的堆顶。 代码在二叉堆操作的基础上稍加改动就行 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364import java.util.Arrays;public class HeapSort &#123; /** * 下沉调整 * * @param array * 待调整的堆 * @param parentIndex * 要下沉的父节点 * @param parentIndex * 堆的有效大小 */ public static void downAdjust(int[] array, int parentIndex, int length) &#123; // temp保存父节点值，用于最后的赋值 int temp = array[parentIndex]; int childIndex = 2 * parentIndex + 1; while (childIndex &lt; length) &#123; // 如果有右孩子，且右孩子大于左孩子的值，则定位到右孩子 if (childIndex + 1 &lt; length &amp;&amp; array[childIndex + 1] &gt; array[childIndex]) &#123; childIndex++; &#125; // 如果父节点小于任何一个孩子的值，直接跳出 if (temp &gt;= array[childIndex]) break; // 无需真正交换，单向赋值即可 array[parentIndex] = array[childIndex]; parentIndex = childIndex; childIndex = 2 * childIndex + 1; &#125; array[parentIndex] = temp; &#125; /** * 堆排序 * * @param array * 待调整的堆 */ public static void heapSort(int[] array) &#123; // 1.把无序数组构建成二叉堆。 for (int i = (array.length - 2) / 2; i &gt;= 0; i--) &#123; downAdjust(array, i, array.length); &#125; System.out.println(Arrays.toString(array)); // [10, 9, 8, 6, 5, 7, 2, 3, 1, 0] // 2.循环删除堆顶元素，移到集合尾部，调节堆产生新的堆顶。 for (int i = array.length - 1; i &gt; 0; i--) &#123; // 最后一个元素和第一元素进行交换 int temp = array[i]; array[i] = array[0]; array[0] = temp; // 下沉调整最大堆 downAdjust(array, 0, i); &#125; &#125; public static void main(String[] args) &#123; int[] arr = new int[] &#123; 1, 3, 2, 6, 5, 7, 8, 9, 10, 0 &#125;; // [0, 1, 2, 3, 5, 6, 7, 8, 9, 10] heapSort(arr); System.out.println(Arrays.toString(arr)); &#125;&#125; 二叉堆的节点下沉调整（downAdjust 方法）是堆排序算法的基础，这个调节操作本身的时间复杂度是多少呢？ 假设二叉堆总共有n个元素，那么下沉调整的最坏时间复杂度就等同于二叉堆的高度，也就是O（logn）。 我们再来回顾一下堆排序算法的步骤： 把无序数组构建成二叉堆。 循环删除堆顶元素，移到集合尾部，调节堆产生新的堆顶。 第一步，把无序数组构建成二叉堆，需要进行n/2次循环。每次循环调用一次 downAdjust 方法，所以第一步的计算规模是 n/2 * logn，时间复杂度O（nlogn）。 第二步，需要进行n-1次循环。每次循环调用一次 downAdjust 方法，所以第二步的计算规模是 （n-1） * logn ，时间复杂度 O（nlogn）。 两个步骤是并列关系，所以整体的时间复杂度同样是 O（nlogn）。","tags":[{"name":"算法","slug":"算法","permalink":"https://imnice.github.io/tags/算法/"}]},{"title":"约瑟夫环问题","date":"2018-10-15T04:08:42.000Z","path":"2018/10/15/约瑟夫环问题/","text":"约瑟夫环问题 问题： Josephus有过的故事：39 个犹太人与Josephus及他的朋友躲到一个洞中，39个犹太人决定宁愿死也不要被敌人抓。于是决定了自杀方式，41个人排成一个圆圈，由第1个人开始报数，每报数到第3人该人就必须自杀。然后下一个重新报数，直到所有人都自杀身亡为止。然而Josephus 和他的朋友并不想遵从，Josephus要他的朋友先假装遵从，他将朋友与自己安排在第16个与第31个位置，于是逃过了这场死亡游戏。 N个人围成一圈，第一个人从1开始报数，报M的将被杀掉，下一个人接着从1开始报。如此反复，最后剩下一个，求最后的胜利者。 思路一：用链表的方法去模拟这个过程，N个人看作是N个链表节点，节点1指向节点2，节点2指向节点3，……，节点N-1指向节点N，节点N指向节点1，这样就形成了一个环。然后从节点1开始1、2、3……往下报数，每报到M，就把那个节点从环上删除。下一个节点接着从1开始报数。最终链表仅剩一个节点。它就是最终的胜利者。缺点：要模拟整个游戏过程，时间复杂度高达O(nm)，当n，m非常大(例如上百万，上千万)的时候，几乎是没有办法在短时间内出结果的。 思路二：约瑟夫环是一个经典的数学问题，我们不难发现这样的依次报数，似乎有规律可循。为了方便导出递推式，我们重新定义一下题目。问题： N个人编号为1，2，……，N，依次报数，每报到M时，杀掉那个人，求最后胜利者的编号。 这边我们先把结论抛出了。之后带领大家一步一步的理解这个公式是什么来的。递推公式： f(N,M)=(f(N−1,M)+M)%N f(N,M)f(N,M)表示，N个人报数，每报到M时杀掉那个人，最终胜利者的编号f(N−1,M)f(N−1,M)表示，N-1个人报数，每报到M时杀掉那个人，最终胜利者的编号下面我们不用字母表示每一个人，而用数字。 1、2、3、4、5、6、7、8、9、10、11 表示11个人，他们先排成一排，假设每报到3的人被杀掉。 刚开始时，头一个人编号是1，从他开始报数，第一轮被杀掉的是编号3的人。 编号4的人从1开始重新报数，这时候我们可以认为编号4这个人是队伍的头。第二轮被杀掉的是编号6的人。 编号7的人开始重新报数，这时候我们可以认为编号7这个人是队伍的头。第三轮被杀掉的是编号9的人。 …… 第九轮时，编号2的人开始重新报数，这时候我们可以认为编号2这个人是队伍的头。这轮被杀掉的是编号8的人。 下一个人还是编号为2的人，他从1开始报数，不幸的是他在这轮被杀掉了。 最后的胜利者是编号为7的人。 1 2 3 4 5 6 7 8 4 5 6 7 8 9 10 11 7 8 9 10 11 1 2 4 10 11 1 2 4 5 7 8 2 4 5 7 8 10 11 7 8 10 11 2 4 11 2 4 7 8 2 7 8 2 7 7 现在再来看我们递推公式是怎么得到的！将上面表格的每一行看成数组，这个公式描述的是：幸存者在这一轮的下标位置 f(1,3)：只有1个人了，那个人就是获胜者，他的下标位置是0f(2,3) = (f(1,3)+3)%2 = 3%2 = 1：在有2个人的时候，胜利者的下标位置为1f(3,3) = (f(2,3)+3)%3 = 4%3 = 1：在有3个人的时候，胜利者的下标位置为1f(4,3) = (f(3,3)+3)%4 = 4%4 = 0：在有4个人的时候，胜利者的下标位置为0……f(11,3) = 6很神奇吧！现在你还怀疑这个公式的正确性吗？上面这个例子验证了这个递推公式的确可以计算出胜利者的下标，下面将讲解怎么推导这个公式。 问题1：假设我们已经知道11个人时，胜利者的下标位置为6。那下一轮10个人时，胜利者的下标位置为多少？答：其实吧，第一轮删掉编号为3的人后，之后的人都往前面移动了3位，胜利这也往前移动了3位，所以他的下标位置由6变成3。 问题2：假设我们已经知道10个人时，胜利者的下标位置为3。那下一轮11个人时，胜利者的下标位置为多少？答：这可以看错是上一个问题的逆过程，大家都往后移动3位，所以f(11,3) = f(10,3)+3不过有可能数组会越界，所以最后模上当前人数的个数，f(11,3) =（f(10,3)+3%11 问题3：现在改为人数改为N，报到M时，把那个人杀掉，那么数组是怎么移动的？答：每杀掉一个人，下一个人成为头，相当于把数组向前移动M位。若已知N-1个人时，胜利者的下标位置位f(N−1,M)，则N个人的时候，就是往后移动M为，(因为有可能数组越界，超过的部分会被接到头上，所以还要模N)，既f(N,M)=(f(N−1,M)+M)%N 注：理解这个递推式的核心在于关注胜利者的下标位置是怎么变的。每杀掉一个人，其实就是把这个数组向前移动了M位。然后逆过来，就可以得到这个递推式。 因为求出的结果是数组中的下标，最终的编号还要加1 1234567891011121314151617181920212223242526272829303132333435363738394041424344import java.util.LinkedList;import java.util.List;public class Josephus &#123; public static void main(String[] args) &#123; System.out.println(solve1(41, 3)); // 31 System.out.println(solve2(41, 3)); // 31 &#125;//思路一：模拟游戏 public static int solve1(int n, int m) &#123; List&lt;Integer&gt; peos = new LinkedList&lt;&gt;(); for (int i = 1; i &lt;= n; i++) &#123; peos.add(i); &#125; int count = 1; int index = 0; while (true) &#123; // 跳出循环条件 if (peos.size() == 1) &#123; return peos.get(0); &#125; // 当数到队尾时再从头开始数 if (index == peos.size()) &#123; index = 0; &#125; // 每次数到m时这个人被杀 if (count == m) &#123; peos.remove(index); index -= 1; // 这个人被杀后这个index已经指向了下一个人，下标减一再加一就行 count = 0; // 计数每次数到m再从1回头数 &#125; count++; index++; &#125; &#125;//思路二：公式分析 public static int solve2(int n, int m) &#123; int p = 0; for (int i = 2; i &lt;= n; i++) &#123; p = (p + m) % i; &#125; return p + 1; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://imnice.github.io/tags/算法/"}]},{"title":"连续子数组的最大和","date":"2018-10-12T04:08:42.000Z","path":"2018/10/12/连续子数组的最大和/","text":"连续子数组的最大和的问题 剑指Offer31leetcode53 问题：求一个数组的子数组最大和 例如输入的数组为{1, -2, 3, 10, -4, 7, 2, -5}，和最大的子数组为｛3, 10, -4, 7, 2}。因此输出为该子数组的和18 。 思路：我们试着从头到尾逐个累加示例数组中的每个数字。初始化和为0。第一步加上第一个数字1， 此时和为1。接下来第二步加上数字-2，和就变成了-1。第三步刷上数字3。我们注意到由于此前累计的和是－1 ，小于0，那如果用-1 加上3 ，得到的和是2 ， 比3 本身还小。也就是说从第一个数字开始的子数组的和会小于从第三个数字开始的子数组的和。因此我们不用考虑从第一个数字开始的子数组，之前累计的和也被抛弃。 我们从第三个数字重新开始累加，此时得到的和是3 。接下来第四步加10，得到和为13 。第五步加上-4， 和为9。我们发现由于-4 是一个负数，因此累加-4 之后得到的和比原来的和还要小。因此我们要把之前得到的和13 保存下来，它有可能是最大的子数组的和。第六步加上数字.7，9 加7 的结果是16，此时和比之前最大的和13 还要大， 把最大的子数组的和由13更新为16。第七步加上2，累加得到的和为18，同时我们也要更新最大子数组的和。第八步加上最后一个数字-5，由于得到的和为13 ，小于此前最大的和18，因此最终最大的子数组的和为18 ，对应的子数组是｛3, 10, -4, 7, 2｝。 1234567891011121314151617181920public class Solution &#123; public int maxSubArray(int[] nums) &#123; // 参数校验 if(nums==null||nums.length==0) return 0; //记录当前的和 int cur=nums[0]; // 记录最大的子数组和 int res=nums[0]; for(int i=1;i&lt;nums.length;i++)&#123; // 如果当前和小于等于0，就重新设置当前和 cur=cur&lt;0?0:cur; // 如果当前和大于0，累加当前和 cur+=nums[i]; // 更新记录到的最大的子数组和 res=Math.max(cur,res); &#125; return res; &#125;&#125;","tags":[{"name":"算法","slug":"算法","permalink":"https://imnice.github.io/tags/算法/"}]},{"title":"计算机网络基础","date":"2018-09-25T04:08:42.000Z","path":"2018/09/25/计算机网络基础/","text":"计算机网络常见的面试题 OSI七层体系结构，以及各层功能、协议 功能 协议 物理层 利用传输介质为数据链路层提供物理连接，实现比特流的透明传输 RJ45、CLOCK、IEEE802.3 数据链路层 在不可靠的物理线路上进行数据的可靠传递。就是保证传输的可靠性。 PPP、FR、HDLC、VLAN、MAC 网络层 负责数据包从源到宿的传递和网际互连 IP、ICMP、ARP、RARP、OSPF、IPX、RIP、IGRP 传输层 提供端到端的可靠报文传递和错误恢复 TCP、UDP、SPX 会话层 建立、管理和终止会话 NFS、SQL、NETBIOS、RPC 表示层 对数据进行翻译、加密和压缩 JPEG、ASCll、DECOIC、加密格式等 应用层 为用户的应用程序(例如电子邮件、文件传输和终端仿真)提供网络服务 HTTP、FTP、TFTP、SMTP、SNMP、DNS、TELNET、HTTPS、POP3、DHCP OSI各层对应的设备和数据单元应用层 计算机：应用程序，如FTP，SMTP，HTTP 应用协议数据单元APDU表示层 计算机：编码方式，图像编解码、URL字段传输编码 表示协议数据单元PPDU会话层 计算机：建立会话，SESSION认证、断点续传 会话协议数据单元SPDU传输层 计算机：进程和端口 数据单元叫做段（Segment）网络层 网络：路由器，防火墙、多层交换机 数据单元叫做分组（数据包：Packet）数据链路层 网络：网卡，网桥，交换机 数据单元叫做帧（Frame）物理层 网络：中继器，集线器、网线、HUB 数据单元叫做比特（Bit） ARP是地址解析协议，简单语言解释一下工作原理。1：首先，每个主机都会在自己的ARP缓冲区中建立一个ARP列表，以表示IP地址和MAC地址之间的对应关系。 2：当源主机要发送数据时，首先检查ARP列表中是否有对应IP地址的目的主机的MAC地址，如果有，则直接发送数据，如果没有，就向本网段的所有主机发送ARP数据包，该数据包包括的内容有：源主机 IP地址，源主机MAC地址，目的主机的IP 地址。 3：当本网络的所有主机收到该ARP数据包时，首先检查数据包中的IP地址是否是自己的IP地址，如果不是，则忽略该数据包，如果是，则首先从数据包中取出源主机的IP和MAC地址写入到ARP列表中，如果已经存在，则覆盖，然后将自己的MAC地址写入ARP响应包中，告诉源主机自己是它想要找的MAC地址。 4：源主机收到ARP响应包后。将目的主机的IP和MAC地址写入ARP列表，并利用此信息发送数据。如果源主机一直没有收到ARP响应数据包，表示ARP查询失败。 广播发送ARP请求，单播发送ARP响应。 各种常见协议的介绍ICMP协议： 因特网控制报文协议。它是TCP/IP协议族的一个子协议，用于在IP主机、路由器之间传递控制消息。 FTP协议： 是TCP/IP协议族中的一个用来在客户机与服务器之间进行简单文件传输的协议，提供不复杂、开销不大的文件传输服务。 HTTP协议： 超文本传输协议，是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。 NAT协议：网络地址转换属接入广域网(WAN)技术，是一种将私有（保留）地址转化为合法IP地址的转换技术， DHCP协议：动态主机配置协议，是一种让系统得以连接到网络上，并获取所需要的配置参数手段，使用UDP协议工作。具体用途：给内部网络或网络服务供应商自动分配IP地址，给用户或者内部网络管理员作为对所有计算机作中央管理的手段。 描述RARP协议RARP是逆地址解析协议，作用是完成硬件地址到IP地址的映射，主要用于无盘工作站，因为给无盘工作站配置的IP地址不能保存。工作流程：在网络中配置一台RARP服务器，里面保存着IP地址和MAC地址的映射关系，当无盘工作站启动后，就封装一个RARP数据包，里面有其MAC地址，然后广播到网络上去，当服务器收到请求包后，就查找对应的MAC地址的IP地址装入响应报文中发回给请求者。因为需要广播请求报文，因此RARP只能用于具有广播能力的网络。 在浏览器中输入www.baidu.com后执行的全部过程(1) 浏览器获取输入的域名www.baidu.com(2) 浏览器向DNS请求解析www.baidu.com的IP地址(3) 域名系统DNS解析出百度服务器的IP地址(4) 浏览器与该服务器建立TCP连接(默认端口号80)(5) 浏览器发出HTTP请求，请求百度首页(6) 服务器通过HTTP响应把首页文件发送给浏览器(7) TCP连接释放(8) 浏览器将首页文件进行解析，并将Web页显示给用户。 TCP和UDP的区别1.基于连接vs无连接。TCP是面向连接的面向字节流协议，而UDP是无连接的面向报文协议。 2.可靠性不同。TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付 。 3.有序性。除了提供交付保证，为TCP也保证了消息的有序性。该消息将以从服务器端发出的同样的顺序发送到客户端，尽管这些消息到网络的另一端时可能是无序的。TCP协议将会为你排好序。UDP不提供任何有序性或序列性的保证。 4.数据边界。TCP不保存数据的边界，而UDP保证。在传输控制协议，数据以字节流的形式发送，并没有明显的标志表明传输信号消息（段）的边界。在UDP中，数据包单独发送的，只有当他们到达时，才会再次集成。包有明确的界限来哪些包已经收到，这意味着在消息发送后，在接收器接口将会有一个读操作，来生成一个完整的消息。虽然TCP也将在收集所有字节之后生成一个完整的消息，但是这些信息在传给传输给接受端之前将储存在TCP缓冲区，以确保更好的使用网络带宽 。 5.速度。TCP速度比较慢，而UDP速度比较快，因为TCP必须创建连接，以保证消息的可靠交付和有序性，他需要做比UDP多的多的事。这就是为什么UDP更适用于对速度比较敏感的应用，例如：在线视频媒体，电视广播和多人在线游戏。 6.重量级vs轻量级。由于上述的开销，TCP被认为是重量级的协议，而与之相比，UDP协议则是一个轻量级的协议。因为UDP传输的信息中不承担任何间接创造连接，保证交货或秩序的的信息。这也反映在用于承载元数据的头的大小。 7.头大小。TCP具有比UDP更大的头。一个TCP数据包报头的大小是20字节，UDP数据报报头是8个字节。TCP报头中包含序列号，ACK号，数据偏移量，保留，控制位，窗口，紧急指针，可选项，填充项，校验位，源端口和目的端口。而UDP报头只包含长度，源端口号，目的端口，和校验和。 8.拥塞或流控制。TCP有流量控制。在任何用户数据可以被发送之前，TCP需要三数据包来设置一个套接字连接。TCP处理的可靠性和拥塞控制。另一方面，UDP不能进行流量控制。 9.用法和应用。在互联网中，TCP和UDP都运行在哪些环境中了？在了解了TCP和UDP之间的关键差异之后，我们可以很容易地得出结论，哪种情况适合他们。由于TCP提供可靠交付和有序性的保证，它是最适合需要高可靠并且对传输时间要求不高的应用。UDP是更适合的应用程序需要快速，高效的传输的应用，如游戏。UDP是无状态的性质，在服务器端需要对大量客户端产生的少量请求进行应答的应用中是非常有用的。在实践中，TCP被用于金融领域，如FIX协议是一种基于TCP的协议，而UDP是大量使用在游戏和娱乐场所。 TCP对应的协议：（1） FTP：定义了文件传输协议，使用21端口。（2） Telnet：一种用于远程登陆的端口，使用23端口，用户可以以自己的身份远程连接到计算机上，可提供基于DOS模式下的通信服务。（3） SMTP：邮件传送协议，用于发送邮件。服务器开放的是25号端口。（4） POP3：它是和SMTP对应，POP3用于接收邮件。POP3协议所用的是110端口。（5）HTTP：是从Web服务器传输超文本到本地浏览器的传送协议。 UDP对应的协议：（1） DNS：用于域名解析服务，将域名地址转换为IP地址。DNS用的是53号端口。（2） SNMP：简单网络管理协议，使用161号端口，是用来管理网络设备的。由于网络设备很多，无连接的服务就体现出其优势。（3） TFTP(Trival File Transfer Protocal)，简单文件传输协议，该协议在熟知端口69上使用UDP服务。 流量控制与拥塞控制流量控制：A与B连接建立后，B根据自己接收缓存的大小确定窗口值大小，然后告知A，A发送的数据不大于该窗口值，往往是点对点之间的通信量控制 拥塞控制：是防止过多的数据注入网络中，根据整个网络的负载进行调整。 三次握手第一次握手client 发送一个SYN(J)包给 server，然后等待 server 的 ACK 回复，进入SYN-SENT状态。p.s: SYN 为 synchronize 的缩写，ACK 为 acknowledgment 的缩写。 第二次握手server 接收到 SYN(seq=J)包后就返回一个ACK(J+1)包以及一个自己的SYN(K)包，然后等待 client 的 ACK 回复，server 进入SYN-RECIVED状态。 第三次握手client 接收到 server 发回的 ACK(J+1)包后，进入ESTABLISHED状态。然后根据 server 发来的 SYN(K)包，返回给等待中的 server 一个ACK(K+1)包。等待中的 server 收到 ACK 回复，也把自己的状态设置为ESTABLISHED。到此 TCP 三次握手完成，client 与 server 可以正常进行通信了。 为什么要进行三次握手我们来看一下为什么需要进行三次握手，两次握手难道不行么？这里我们用一个生活中的具体例子来解释就很好理解了。我们可以将三次握手中的客户端和服务器之间的握手过程比喻成 A 和 B 通信的过程： 在第一次通信过程中，A 向 B 发送信息之后，B 收到信息后可以确认自己的收信能力和 A 的发信能力没有问题。 在第二次通信中，B 向 A 发送信息之后，A 可以确认自己的发信能力和 B 的收信能力没有问题，但是 B 不知道自己的发信能力到底如何，所以就需要第三次通信。 在第三次通信中，A 向 B 发送信息之后，B 就可以确认自己的发信能力没有问题。 四次挥手由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。（1）客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送（报文段4）。（2）服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1（报文段5）。和SYN一样，一个FIN将占用一个序号。（3）服务器B关闭与客户端A的连接，发送一个FIN给客户端A（报文段6）。（4）客户端A发回ACK报文确认，并将确认序号设置为收到序号加1（报文段7） TCP采用四次挥手关闭连接如图所示为什么建立连接协议是三次握手，而关闭连接却是四次握手呢？这是因为服务端的LISTEN状态下的SOCKET当收到SYN报文的建连请求后，它可以把ACK和SYN（ACK起应答作用，而SYN起同步作用）放在一个报文里来发送。但关闭连接时，当收到对方的FIN报文通知时，它仅仅表示对方没有数据发送给你了；但未必你所有的数据都全部发送给对方了，所以你可以未必会马上会关闭SOCKET,也即你可能还需要发送一些数据给对方之后，再发送FIN报文给对方来表示你同意现在可以关闭连接了，所以它这里的ACK报文和FIN报文多数情况下都是分开发送的。","tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://imnice.github.io/tags/计算机网络/"}]},{"title":"Java集合框架小结","date":"2018-09-22T04:08:42.000Z","path":"2018/09/22/Java集合框架小结/","text":"Java集合框架小结 Vector、ArrayList和LinkedList的比较 Vector ArrayList LinkedList 底层结构 数组 数组 双向链表 插/查速度 查询快，插入慢 查询快，插入慢 查询慢，插入快 初始化默认容量 10（每次扩容一倍） 10（每次扩容1.5倍） —— 是否线程安全 是 否 否 ArrayList：线程不同步。默认初始容量为 10，当数组大小不足时容量扩大为 1.5 倍。为追求效率，ArrayList 没有实现同步（synchronized），如果需要多个线程并发访问，用户可以手动同步，也可使用 Vector 替代。 (注意：List list = new ArrayList(20);这条语句list不会扩容，直接创建了一个20容量的list )删除元素：需要调用 System.arraycopy() 将 index+1 后面的元素都复制到 index 位置上。扩容：添加元素时使用 ensureCapacityInternal() 方法来保证容量足够，如果不够时，需要使用 grow() 方法进行扩容，新容量的大小为 oldCapacity + (oldCapacity &gt;&gt; 1)，也就是旧容量的 1.5 倍。扩容操作需要调用 Arrays.copyOf() 把原数组整个复制到新数组中，这个操作代价很高，因此最好在创建 ArrayList 对象时就指定大概的容量大小，减少扩容操作的次数。 LinkedList：线程不同步。双向链接实现。LinkedList 同时实现了 List 接口和 Deque 接口，也就是说它既可以看作一个顺序容器，又可以看作一个队列（Queue），同时又可以看作一个栈（Stack）。这样看来，LinkedList 简直就是个全能冠军。当你需要使用栈或者队列时，可以考虑使用 LinkedList，一方面是因为 Java 官方已经声明不建议使用 Stack 类，更遗憾的是，Java 里根本没有一个叫做 Queue 的类（它是个接口名字）。关于栈或队列，现在的首选是 ArrayDeque，它有着比 LinkedList（当作栈或队列使用时）有着更好的性能。 ArrayList 与 LinkedList ArrayList 基于动态数组实现，LinkedList 基于双向链表实现； ArrayList 支持随机访问，LinkedList 不支持； LinkedList 在任意位置添加删除元素更快。 Stack and Queue：Java 里有一个叫做 Stack 的类，却没有叫做 Queue 的类（它是个接口名字）。当需要使用栈时，Java 已不推荐使用 Stack，而是推荐使用更高效的 ArrayDeque；既然 Queue 只是一个接口，当需要使用队列时也就首选 ArrayDeque 了（次选是 LinkedList ）。 Vector：线程同步。默认初始容量为 10，当数组大小不足时容量扩大为 2 倍。它的同步是通过 Iterator 方法加 synchronized 实现的。 synchronizedList封装ArrayList（LinkedList）得到线程安全的List为了获得线程安全的 ArrayList，可以使用 Collections.synchronizedList(); 得到一个线程安全的 ArrayList。12List&lt;String&gt; list = new ArrayList&lt;&gt;();List&lt;String&gt; synList = Collections.synchronizedList(list); Stack：线程同步。继承自 Vector，添加了几个方法来完成栈的功能。现在已经不推荐使用 Stack，在栈和队列中有限使用 ArrayDeque，其次是 LinkedList。 HashMap浅析数据存储结构在 1.7 之前 JDK 采用「拉链法」来存储数据，即数组和链表结合的方式。「拉链法」用专业点的名词来说叫做链地址法。简单来说，就是数组加链表的结合。在每个数组元素上存储的都是一个链表。我们之前说到不同的 key 可能经过 hash 运算可能会得到相同的地址，但是一个数组单位上只能存放一个元素，采用链地址法以后，如果遇到相同的 hash 值的 key 的时候，我们可以将它放到作为数组元素的链表上。待我们去取元素的时候通过 hash 运算的结果找到这个链表，再在链表中找到与 key 相同的节点，就能找到 key 相应的值了。JDK1.7 中新添加进来的元素总是放在数组相应的角标位置，而原来处于该角标的位置的节点作为 next 节点放到新节点的后边。 JDK1.8 之后的 HashMap 底层在解决哈希冲突的时候，就不单单是使用数组加上单链表的组合了，因为当处理如果 hash 值冲突较多的情况下，链表的长度就会越来越长，此时通过单链表来寻找对应 Key 对应的 Value 的时候就会使得时间复杂度达到 O(n)，因此在 JDK1.8 之后，在链表新增节点导致链表长度超过 TREEIFY_THRESHOLD = 8 的时候，就会在添加元素的同时将原来的单链表转化为红黑树。黑树是一种易于增删改查的二叉树，他对与数据的查询的时间复杂度是 O(logn) 级别，所以利用红黑树的特点就可以更高效的对 HashMap 中的元素进行操作。 这里需要讲明白两个问题：数据底层具体存储的是什么？这样的存储方式有什么优点呢？ （1）从源码可知，HashMap 类中有一个非常重要的字段，就是 Node[] table，即哈希桶数组，明显它是一个 Node 的数组。我们来看 Node（ JDK1.8 中） 是何物。 1234567891011121314static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; //用来定位数组索引位置 final K key; V value; Node&lt;K,V&gt; next; //链表的下一个node Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; ... &#125; public final K getKey()&#123; ... &#125; public final V getValue() &#123; ... &#125; public final String toString() &#123; ... &#125; public final int hashCode() &#123; ... &#125; public final V setValue(V newValue) &#123; ... &#125; public final boolean equals(Object o) &#123; ... &#125;&#125; Node 是 HashMap 的一个内部类，实现了 Map.Entry 接口，本质是就是一个映射（键值对）。上图中的每个黑色圆点就是一个Node对象。 （2）HashMap 就是使用哈希表来存储的。哈希表为解决冲突，可以采用开放地址法和链地址法等来解决问题， Java 中 HashMap 采用了链地址法。链地址法，简单来说，就是数组加链表的结合。在每个数组元素上都一个链表结构，当数据被 Hash 后，得到数组下标，把数据放在对应下标元素的链表上。例如程序执行下面代码： 1map.put(\"美团\",\"小美\"); 系统将调用 “美团” 这个 key 的 hashCode() 方法得到其 hashCode 值（该方法适用于每个 Java 对象），然后再通过 Hash 算法的后两步运算（高位运算和取模运算，下文有介绍）来定位该键值对的存储位置，有时两个 key 会定位到相同的位置，表示发生了 Hash 碰撞。当然 Hash 算法计算结果越分散均匀，Hash 碰撞的概率就越小，map 的存取效率就会越高。 如果哈希桶数组很大，即使较差的 Hash 算法也会比较分散，如果哈希桶数组数组很小，即使好的 Hash 算法也会出现较多碰撞，所以就需要在空间成本和时间成本之间权衡，其实就是在根据实际情况确定哈希桶数组的大小，并在此基础上设计好的 hash 算法减少 Hash 碰撞。 那么通过什么方式来控制 map 使得 Hash 碰撞的概率又小，哈希桶数组（Node[] table）占用空间又少呢？ 答案就是好的 Hash 算法和扩容机制。 在理解 Hash 和扩容流程之前，我们得先了解下 HashMap 的几个字段。从 HashMap 的默认构造函数源码可知，构造函数就是对下面几个字段进行初始化，源码如下： 1234int threshold; // 所能容纳的key-value对极限 final float loadFactor; // 负载因子int modCount; int size; 首先，Node[] table的初始化长度 length (默认值是16)，Load factor 为负载因子(默认值是0.75)，threshold 是 HashMap 所能容纳的最大数据量的 Node (键值对)个数。threshold = length * Load factor。也就是说，在数组定义好长度之后，负载因子越大，所能容纳的键值对个数越多。 结合负载因子的定义公式可知，threshold 就是在此 Load factor 和 length (数组长度)对应下允许的最大元素数目，超过这个数目就重新 resize(扩容)，扩容后的 HashMap 容量是之前容量的两倍。默认的负载因子 0.75 是对空间和时间效率的一个平衡选择，建议大家不要修改，除非在时间和空间比较特殊的情况下，如果内存空间很多而又对时间效率要求很高，可以降低负载因子 Load factor 的值；相反，如果内存空间紧张而对时间效率要求不高，可以增加负载因子 loadFactor 的值，这个值可以大于1。 size 这个字段其实很好理解，就是 HashMap 中实际存在的键值对数量。注意和 table 的长度 length、容纳最大键值对数量 threshold 的区别。而 modCount 字段主要用来记录 HashMap 内部结构发生变化的次数，主要用于迭代的快速失败。强调一点，内部结构发生变化指的是结构发生变化，例如 put 新键值对，但是某个 key 对应的 value 值被覆盖不属于结构变化。 在 HashMap 中，哈希桶数组 table 的长度 length 大小必须为$2^n$（一定是合数），这是一种非常规的设计，常规的设计是把桶的大小设计为素数。相对来说素数导致冲突的概率要小于合数，具体证明可以参考 为什么一般hashtable的桶数会取一个素数？ ，Hashtable 初始化桶大小为 11，就是桶大小设计为素数的应用（Hashtable 扩容后不能保证还是素数）。HashMap 采用这种非常规设计，主要是为了在取模和扩容时做优化，同时为了减少冲突，HashMap 定位哈希桶索引位置时，也加入了高位参与运算的过程。 这里存在一个问题，即使负载因子和 Hash 算法设计的再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。于是，在 JDK1.8 版本中，对数据结构做了进一步的优化，引入了红黑树。而当链表长度太长（默认超过8）时，链表就转换为红黑树，利用红黑树快速增删改查的特点提高 HashMap 的性能，其中会用到红黑树的插入、删除、查找等算法。本文不再对红黑树展开讨论，想了解更多红黑树数据结构的工作原理可以参考：教你初步了解红黑树。 重要参数 参数 说明 buckets 在 HashMap 的注释里使用哈希桶来形象的表示数组中每个地址位置。注意这里并不是数组本身，数组是装哈希桶的，他可以被称为哈希表。 capacity table 的容量大小，默认为 16。需要注意的是 capacity 必须保证为 2 的 n 次方。 size table 的实际使用量。 threshold size 的临界值，size 必须小于 threshold，如果大于等于，就必须进行扩容操作。 loadFactor 装载因子，table 能够使用的比例，threshold = capacity * loadFactor。 TREEIFY_THRESHOLD 树化阀值，哈希桶中的节点个数大于该值（默认为8）的时候将会被转为红黑树行存储结构。 UNTREEIFY_THRESHOLD 非树化阀值，小于该值（默认为 6）的时候将再次改为单链表的格式存储 HashMap的put方法 HashMap与HashTable HashTable 使用 synchronized 来进行同步。 HashMap 可以插入键为 null 的 Entry。 HashMap 的迭代器是 fail-fast 迭代器。 HashMap 不能保证随着时间的推移 Map 中的元素次序是不变的。 什么是 fail-fast 机制?fail-fast 机制在遍历一个集合时，当集合结构被修改，会抛出 Concurrent Modification Exception。 fail-fast 会在以下两种情况下抛出 Concurrent Modification Exception （1）单线程环境 集合被创建后，在遍历它的过程中修改了结构。 注意 remove() 方法会让 expectModcount 和 modcount 相等，所以是不会抛出这个异常。 （2）多线程环境 当一个线程在遍历这个集合，而另一个线程对这个集合的结构进行了修改。 modCount 用来记录 ArrayList 结构发生变化的次数。结构发生变化是指添加或者删除至少一个元素的所有操作，或者是调整内部数组的大小，仅仅只是设置元素的值不算结构发生变化。 在进行序列化或者迭代等操作时，需要比较操作前后 modCount 是否改变，如果改变了需要抛出 Concurrent Modification Exception。 1234567891011121314151617private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125; 小结 扩容是一个特别耗性能的操作，所以当程序员在使用 HashMap 的时候，估算 map 的大小，初始化的时候给一个大致的数值，避免 map 进行频繁的扩容。 负载因子是可以修改的，也可以大于1，但是建议不要轻易修改，除非情况非常特殊。 HashMap 是线程不安全的，不要在并发的环境中同时操作 HashMap，建议使用 ConcurrentHashMap。 JDK1.8 引入红黑树大程度优化了 HashMap 的性能。 ConcurrentHashMap浅析哈希表是中非常高效，复杂度为 O(1) 的数据结构，在 Java 开发中，我们最常见到最频繁使用的就是 HashMap 和 HashTable，但是在线程竞争激烈的并发场景中使用都不够合理。 HashMap ：先说 HashMap，HashMap 是线程不安全的，在并发环境下，可能会形成环状链表（扩容时可能造成），导致 get 操作时，cpu 空转，所以，在并发环境中使 用HashMap 是非常危险的。 HashTable ： HashTable 和 HashMap的实现原理几乎一样，差别无非是：（1）HashTable不允许key和value为null；（2）HashTable是线程安全的。 但是 HashTable 线程安全的策略实现代价却太大了，简单粗暴，get/put 所有相关操作都是 synchronized 的，这相当于给整个哈希表加了一把大锁，多线程访问时候，只要有一个线程访问或操作该对象，那其他线程只能阻塞，相当于将所有的操作串行化，在竞争激烈的并发场景中性能就会非常差。 HashTable 性能差主要是由于所有操作需要竞争同一把锁，而如果容器中有多把锁，每一把锁锁一段数据，这样在多线程访问时不同段的数据时，就不会存在锁竞争了，这样便可以有效地提高并发效率。这就是ConcurrentHashMap 所采用的 “分段锁“ 思想。 存储结构ConcurrentHashMap 采用了非常精妙的”分段锁”策略，ConcurrentHashMap 的主干是个 Segment 数组。 1final Segment&lt;K,V&gt;[] segments; Segment 继承了 ReentrantLock，所以它就是一种可重入锁（ReentrantLock)。在 ConcurrentHashMap，一个 Segment 就是一个子哈希表，Segment 里维护了一个 HashEntry 数组，并发环境下，对于不同 Segment 的数据进行操作是不用考虑锁竞争的。（就按默认的 ConcurrentLeve 为16来讲，理论上就允许 16 个线程并发执行，有木有很酷） 所以，对于同一个 Segment 的操作才需考虑线程同步，不同的 Segment 则无需考虑。 Segment 类似于 HashMap，一个 Segment 维护着一个 HashEntry 数组 1transient volatile HashEntry&lt;K,V&gt;[] table; HashEntry 是目前我们提到的最小的逻辑处理单元了。一个 ConcurrentHashMap 维护一个 Segment 数组，一个 Segment 维护一个 HashEntry 数组。 123456static final class HashEntry&lt;K,V&gt; &#123; final int hash; final K key; volatile V value; volatile HashEntry&lt;K,V&gt; next;&#125; ConcurrentHashMap 和 HashMap 实现上类似，最主要的差别是 ConcurrentHashMap 采用了分段锁（Segment），每个分段锁维护着几个桶（HashEntry），多个线程可以同时访问不同分段锁上的桶，从而使其并发度更高（并发度就是 Segment 的个数）。 Segment 继承自 ReentrantLock。 1234567891011121314151617static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; static final int MAX_SCAN_RETRIES = Runtime.getRuntime().availableProcessors() &gt; 1 ? 64 : 1; transient volatile HashEntry&lt;K,V&gt;[] table; transient int count; transient int modCount; transient int threshold; final float loadFactor;&#125; 1final Segment&lt;K,V&gt;[] segments; 默认的并发级别为 16，也就是说默认创建 16 个 Segment。 1static final int DEFAULT_CONCURRENCY_LEVEL = 16; size 操作每个 Segment 维护了一个 count 变量来统计该 Segment 中的键值对个数。 12345/** * The number of elements. Accessed only either within locks * or among other volatile reads that maintain visibility. */transient int count; 在执行 size 操作时，需要遍历所有 Segment 然后把 count 累计起来。 ConcurrentHashMap 在执行 size 操作时先尝试不加锁，如果连续两次不加锁操作得到的结果一致，那么可以认为这个结果是正确的。 尝试次数使用 RETRIES_BEFORE_LOCK 定义，该值为 2，retries 初始值为 -1，因此尝试次数为 3。 如果尝试的次数超过 3 次，就需要对每个 Segment 加锁。 同步方式Segment 继承自 ReentrantLock，所以我们可以很方便的对每一个 Segment 上锁。 对于读操作，获取 Key 所在的 Segment 时，需要保证可见性。具体实现上可以使用 volatile 关键字，也可使用锁。但使用锁开销太大，而使用 volatile 时每次写操作都会让所有 CPU 内缓存无效，也有一定开销。ConcurrentHashMap 使用如下方法保证可见性，取得最新的 Segment。 1Segment&lt;K,V&gt; s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u) 获取 Segment 中的 HashEntry 时也使用了类似方法 12HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE) 对于写操作，并不要求同时获取所有 Segment 的锁，因为那样相当于锁住了整个 Map。它会先获取该 Key-Value 对所在的 Segment 的锁，获取成功后就可以像操作一个普通的 HashMap 一样操作该 Segment，并保证该Segment 的安全性。同时由于其它 Segment 的锁并未被获取，因此理论上可支持 concurrencyLevel（等于 Segment 的个数）个线程安全的并发读写。 获取锁时，并不直接使用 lock 来获取，因为该方法获取锁失败时会挂起。事实上，它使用了自旋锁，如果 tryLock 获取锁失败，说明锁被其它线程占用，此时通过循环再次以 tryLock 的方式申请锁。如果在循环过程中该 Key 所对应的链表头被修改，则重置 retry 次数。如果 retry 次数超过一定值，则使用 lock 方法申请锁。 这里使用自旋锁是因为自旋锁的效率比较高，但是它消耗 CPU 资源比较多，因此在自旋次数超过阈值时切换为互斥锁。 JDK 1.8 的改动 JDK 1.7 使用分段锁机制来实现并发更新操作，核心类为 Segment，它继承自重入锁 ReentrantLock，并发程度与 Segment 数量相等。 JDK 1.8 使用了 CAS 操作来支持更高的并发度，在 CAS 操作失败时使用内置锁 synchronized。 并且 JDK 1.8 的实现也在链表过长时会转换为红黑树。 HashSet 前面已经说过 HashSet 是对 HashMap 的简单包装，对 HashSet 的函数调用都会转换成合适的 HashMap 方法，因此 HashSet 的实现非常简单，只有不到 300 行代码（适配器模式）。这里不再赘述。 12345678910111213141516//HashSet是对HashMap的简单包装public class HashSet&lt;E&gt;&#123; ...... private transient HashMap&lt;E,Object&gt; map;//HashSet里面有一个HashMap // Dummy value to associate with an Object in the backing Map private static final Object PRESENT = new Object(); public HashSet() &#123; map = new HashMap&lt;&gt;(); &#125; ...... public boolean add(E e) &#123;//简单的方法转换 return map.put(e, PRESENT)==null; &#125; ......&#125; 成员变量首先了解下 HashSet 的成员变量: 1234private transient HashMap&lt;E,Object&gt; map;// Dummy value to associate with an Object in the backing Mapprivate static final Object PRESENT = new Object(); 发现主要就两个变量: map ：用于存放最终数据的。 PRESENT ：是所有写入 map 的 value 值。 构造函数1234567public HashSet() &#123; map = new HashMap&lt;&gt;();&#125;public HashSet(int initialCapacity, float loadFactor) &#123; map = new HashMap&lt;&gt;(initialCapacity, loadFactor);&#125; 构造函数很简单，利用了 HashMap 初始化了 map 。 add()123public boolean add(E e) &#123; return map.put(e, PRESENT)==null;&#125; 比较关键的就是这个 add() 方法。 可以看出它是将存放的对象当做了 HashMap 的健，value 都是相同的 PRESENT 。由于 HashMap 的 key 是不能重复的，所以每当有重复的值写入到 HashSet 时，value 会被覆盖，但 key 不会收到影响，这样就保证了 HashSet 中只能存放不重复的元素。 LinkedHashMap经典用法LinkedHashMap 除了可以保证迭代顺序外，还有一个非常有用的用法：可以轻松实现一个采用了FIFO替换策略的缓存。具体说来，LinkedHashMap 有一个子类方法 protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest)，该方法的作用是告诉 Map 是否要删除“最老”的 Entry，所谓最老就是当前 Map 中最早插入的 Entry，如果该方法返回 true，最老的那个元素就会被删除。在每次插入新元素的之后 LinkedHashMap 会自动询问 removeEldestEntry() 是否要删除最老的元素。这样只需要在子类中重载该方法，当元素个数超过一定数量时让 removeEldestEntry() 返回 true，就能够实现一个固定大小的 FIFO 策略的缓存。示例代码如下： 12345678910111213/** 一个固定大小的FIFO替换策略的缓存 */class FIFOCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt;&#123; private final int cacheSize; public FIFOCache(int cacheSize)&#123; this.cacheSize = cacheSize; &#125; // 当Entry个数超过cacheSize时，删除最老的Entry @Override protected boolean removeEldestEntry(Map.Entry&lt;K,V&gt; eldest) &#123; return size() &gt; cacheSize; &#125;&#125; 容器中的设计模式迭代器模式 Collection 实现了 Iterable 接口，其中的 iterator() 方法能够产生一个 Iterator 对象，通过这个对象就可以迭代遍历 Collection 中的元素。 从 JDK 1.5 之后可以使用 foreach 方法来遍历实现了 Iterable 接口的聚合对象。 123456List&lt;String&gt; list = new ArrayList&lt;&gt;();list.add(\"a\");list.add(\"b\");for (String item : list) &#123; System.out.println(item);&#125; 适配器模式java.util.Arrays.asList() 可以把数组类型转换为 List 类型。 12@SafeVarargspublic static &lt;T&gt; List&lt;T&gt; asList(T... a) 如果要将数组类型转换为 List 类型，应该注意的是 asList() 的参数为泛型的变长参数，因此不能使用基本类型数组作为参数，只能使用相应的包装类型数组。 12Integer[] arr = &#123;1, 2, 3&#125;;List list = Arrays.asList(arr); 也可以使用以下方式生成 List。 1List list = Arrays.asList(1,2,3); 面试指南1. ArrayList和LinkedList区别 ArrayList 和 LinkedList 可想从名字分析，它们一个是 Array (动态数组) 的数据结构，一个是 Link (链表) 的数据结构，此外，它们两个都是对 List 接口的实现。前者是数组队列，相当于动态数组；后者为双向链表结构，也可当作堆栈、队列、双端队列； 当随机访问 List 时（get和set操作），ArrayList 比 LinkedList的效率更高，因为 LinkedList 是线性的数据存储方式，所以需要移动指针从前往后依次查找； 当对数据进行增加和删除的操作时（add 和 remove 操作），LinkedList 比 ArrayList 的效率更高，因为 ArrayList 是数组，所以在其中进行增删操作时，会对操作点之后所有数据的下标索引造成影响，需要进行数据的移动； 从利用效率来看，ArrayList 自由性较低，因为它需要手动的设置固定大小的容量，但是它的使用比较方便，只需要创建，然后添加数据，通过调用下标进行使用；而 LinkedList 自由性较高，能够动态的随数据量的变化而变化，但是它不便于使用； ArrayList 主要空间开销在于需要在 List 列表预留一定空间；而 LinkList 主要控件开销在于需要存储结点信息以及结点指针信息。 ArrayList、LinkedList 和 Vector如何选择？ 当对数据的主要操作为索引或只在集合的末端增加、删除元素时，使用 ArrayList 或 Vector 效率比较高； 当对数据的操作主要为制定位置的插入或删除操作时，使用 LinkedList 效率比较高； 当在多线程中使用容器时（即多个线程会同时访问该容器），选用 Vector 较为安全； 2. HashMap和HashTable区别，HashMap的key类型 Hash Map和HashTable的区别 Hashtable 的方法是同步的，HashMap 非同步，所以在多线程场合要手动同步 Hashtable 不允许 null 值 (key 和 value 都不可以)，HashMap 允许 null 值( key 和 value 都可以)。 两者的遍历方式大同小异，Hashtable 仅仅比 HashMap 多一个 elements 方法。 Hashtable 和 HashMap 都能通过 values() 方法返回一个 Collection ，然后进行遍历处理。 两者也都可以通过 entrySet() 方法返回一个 Set ， 然后进行遍历处理。 HashTable 使用 Enumeration，HashMap 使用 Iterator。 哈希值的使用不同，Hashtable 直接使用对象的 hashCode。而 HashMap 重新计算hash值，而且用于代替求模。 Hashtable 中 hash 数组默认大小是11，增加的方式是 old*2+1。HashMap 中 hash 数组的默认大小是16，而且一定是 2 的指数。 HashTable 基于 Dictionary 类，而 HashMap 基于 AbstractMap 类 HashMap中的key可以是任何对象或数据类型吗 可以为null，但不能是可变对象，如果是可变对象的话，对象中的属性改变，则对象 HashCode 也进行相应的改变，导致下次无法查找到已存在Map中的数据。 如果可变对象在 HashMap 中被用作键，那就要小心在改变对象状态的时候，不要改变它的哈希值了。我们只需要保证成员变量的改变能保证该对象的哈希值不变即可。 HashTable是线程安全的么 HashTable 是线程安全的，其实现是在对应的方法上添加了 synchronized 关键字进行修饰，由于在执行此方法的时候需要获得对象锁，则执行起来比较慢。所以现在如果为了保证线程安全的话，使用 CurrentHashMap。 3. HashMap和ConcurrentHashMap HashMap和Concurrent HashMap区别？ HashMa p是非线程安全的，CurrentHashMap 是线程安全的。 ConcurrentHashMap 将整个 Hash 桶进行了分段 segment，也就是将这个大的数组分成了几个小的片段segment，而且每个小的片段 segment 上面都有锁存在，那么在插入元素的时候就需要先找到应该插入到哪一个片段 segment，然后再在这个片段上面进行插入，而且这里还需要获取 segment 锁。 ConcurrentHashMap 让锁的粒度更精细一些，并发性能更好。 ConcurrentHashMap 线程安全吗， ConcurrentHashMap如何保证 线程安全？ HashTable 容器在竞争激烈的并发环境下表现出效率低下的原因是所有访问 HashTable 的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是 ConcurrentHashMap 所使用的分段锁，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 get 操作的高效之处在于整个 get 过程不需要加锁，除非读到的值是空的才会加锁重读。get 方法里将要使用的共享变量都定义成 volatile，如用于统计当前 Segement 大小的 count 字段和用于存储值的 HashEntry 的 value。定义成 volatile 的变量，能够在线程之间保持可见性，能够被多线程同时读，并且保证不会读到过期的值，但是只能被单线程写（有一种情况可以被多线程写，就是写入的值不依赖于原值），在 get 操作里只需要读不需要写共享变量 count 和 value，所以可以不用加锁。 put 方法首先定位到 Segment，然后在 Segment 里进行插入操作。 插入操作需要经历两个步骤：（1）判断是否需要对 Segment 里的 HashEntry 数组进行扩容；（2）定位添加元素的位置然后放在HashEntry数组里。 4. Hashtable的原理Hashtable 使用链地址法进行元素存储，关键字：链地址，头插法。 Hashtable 与 HashMap 的简单比较 HashTable 基于 Dictionary 类，而 HashMap 是基于 AbstractMap。Dictionary 是任何可将键映射到相应值的类的抽象父类，而 AbstractMap 是基于 Map 接口的实现，它以最大限度地减少实现此接口所需的工作。 HashMap 的 key 和 value 都允许为 null，而 Hashtable 的 key 和 value 都不允许为 null。HashMap 遇到 key 为 null 的时候，调用 putForNullKey 方法进行处理，而对 value 没有处理；Hashtable遇到 null，直接返回 NullPointerException。 Hashtable 方法是同步，而HashMap则不是。我们可以看一下源码，Hashtable 中的几乎所有的 public 的方法都是 synchronized 的，而有些方法也是在内部通过 synchronized 代码块来实现。所以有人一般都建议如果是涉及到多线程同步时采用 HashTable，没有涉及就采用 HashMap，但是在 Collections 类中存在一个静态方法：synchronizedMap()，该方法创建了一个线程安全的 Map 对象，并把它作为一个封装的对象来返回。 参考资料： Hashtable 的实现原理 - Java 集合学习指南 - 极客学院Wiki 5. Hash冲突的解决办法 链地址法 开放地址法（向后一位） 线性探测 平方探测 二次哈希 再哈希法 6. 什么是迭代器 Java 集合框架的集合类，我们有时候称之为容器。容器的种类有很多种，比如 ArrayList、LinkedList、HashSet…，每种容器都有自己的特点，ArrayList 底层维护的是一个数组；LinkedList 是链表结构的；HashSet 依赖的是哈希表，每种容器都有自己特有的数据结构。 因为容器的内部结构不同，很多时候可能不知道该怎样去遍历一个容器中的元素。所以为了使对容器内元素的操作更为简单，Java 引入了迭代器模式！ 把访问逻辑从不同类型的集合类中抽取出来，从而避免向外部暴露集合的内部结构。 迭代器模式：就是提供一种方法对一个容器对象中的各个元素进行访问，而又不暴露该对象容器的内部细。 1234567891011121314151617public static void main(String[] args) &#123; // 使用迭代器遍历ArrayList集合 Iterator&lt;String&gt; listIt = list.iterator(); while(listIt.hasNext())&#123; System.out.println(listIt.hasNext()); &#125; // 使用迭代器遍历Set集合 Iterator&lt;String&gt; setIt = set.iterator(); while(setIt.hasNext())&#123; System.out.println(listIt.hasNext()); &#125; // 使用迭代器遍历LinkedList集合 Iterator&lt;String&gt; linkIt = linkList.iterator(); while(linkIt.hasNext())&#123; System.out.println(listIt.hasNext()); &#125;&#125; 参考资料： 深入理解Java中的迭代器 - Mr·Dragon - 博客园 7. 构造相同hash的字符串进行攻击，这种情况应该怎么处理？JDK7如何处理攻击原理： 当客户端发送一个请求到服务器，如果该请求中带有参数，服务器端会将 参数名-参数值 作为 key-value 保存在 HashMap 中。如果有人恶意构造请求，在请求中加入大量相同 hash 值的 String 参数名（key），那么在服务器端用于存储这些 key-value 对的 HashMap 会被强行退化成链表，如图： 如果数据量足够大，那么在查找，插入时会占用大量 CPU，达到拒绝服务攻击的目的。 怎么处理 限制 POST 和 GET 请求的参数个数 限制 POST 请求的请求体大小 Web Application FireWall（WAF） JDK7如何处理 HashMap 会动态的使用一个专门 TreeMap 实现来替换掉它。 8. Hashmap为什么大小是2的幂次首先来看一下 hashmap 的 put 方法的源码 1234567891011121314151617181920212223public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); //将空key的Entry加入到table[0]中 int hash = hash(key.hashCode()); //计算key.hashcode()的hash值，hash函数由hashmap自己实现 int i = indexFor(hash, table.length); //获取将要存放的数组下标 /* * for中的代码用于：当hash值相同且key相同的情况下，使用新值覆盖旧值（其实就是修改功能） */ //注意：for循环在第一次执行时就会先判断条件 for (Entry&lt;K, V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; //hash值相同且key相同的情况下，使用新值覆盖旧值 if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; //e.recordAccess(this); return oldValue;//返回旧值 &#125; &#125; modCount++; addEntry(hash, key, value, i);//增加一个新的Entry到table[i] return null;//如果没有与传入的key相等的Entry，就返回null&#125; 123456/** * \"按位与\"来获取数组下标 */static int indexFor(int h, int length) &#123; return h &amp; (length - 1);&#125; hashmap 始终将自己的桶保持在2的幂次，这是为什么？indexFor这个方法解释了这个问题 大家都知道计算机里面位运算是基本运算，位运算的效率是远远高于取余 % 运算的 举个例子：2的幂次 转换成二进制就是 1+n 个 0，减 1 之后就是 0+n个1，如16 -&gt; 10000，15 -&gt; 01111 那么根据 &amp; 位运算的规则，都为 1 (真)时，才为 1，那 0≤运算后的结果≤15，假设 h &lt;= 15，那么运算后的结果就是 h 本身，h &gt;15，运算后的结果就是最后四位二进制做 &amp; 运算后的值，最终，就是 % 运算后的余数。 当容量一定是 2的幂次时，h &amp; (length - 1) == h % length","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://imnice.github.io/tags/Java基础/"}]},{"title":"Java基础面试题（二）","date":"2018-09-19T07:08:42.000Z","path":"2018/09/19/Java基础面试题（二）/","text":"Java基础面试题（二） 操作系统中 heap 和 stack 的区别堆为队列优先，先进先出（FIFO）。栈为先进后出（FILO）。 一、空间分配：​ 1.堆（操作系统）：一般由程序员分配释放，若程序员不释放，程序结束时可能由OS回收，分配方式类似于链表。PS：java中都是系统GC，程序员无法进行GC。​ 2.栈（操作系统）：由操作系统自动分配释放，存放函数的参数值，局部变量值等。操作方式与数据结构中的栈相类似。二、缓存方式：​ 1.堆：使用二级缓存，生命周期与虚拟机的GC算法有关（并不是引用为空就立即被GC），调用速度相对较低。​ 2.栈：使用一级缓存，被调用时通常处于存储空间中，调用后被立即释放。三、数据结构：​ 1、堆（数据结构）：类似于树结构，可以类比于堆排序​ 2、栈（数据结构）：先进后出（FILO）JAVA中的区别：​ 堆（heap）与栈（stack）都是java在RAM中用来存放数据的地方。与C++不同的是，java自动管理堆（heap）和（栈），程序员不能直接的设置堆和栈。​ 栈：在函数中定义的一些基本类型的变量和对象的引用变量都在函数的栈内存中分配。当在一段代码块中定义一个变量时，java就在栈中为这个变量分配内存空间，当超过变量的作用域后，Java会自动释放掉为该变量所分配的内存空间，该内存空间可以立即被用作他用。​ 堆：对内存用来存放由new创建的对象和数组，在堆中分配的内存，由java虚拟机的自动垃圾回收器来管理。在堆中产生一个数组或对象后，还可以在栈中定义一个特殊的变量，让栈中的这个变量的取值等于数组或对象在堆内存中的首地址，栈中的这个变量就成了数组或对象的引用变量。 什么是对象关系映射ORM?对象关系映射（Object Relational Mapping，简称ORM）是通过使用描述对象和数据库之间映射的元数据，将面向对象语言程序中的对象自动持久化到关系数据库中。本质上就是将数据从一种形式转换到另外一种形式。 什么是 Java 的反射机制 Java反射机制是在运行状态中，对于任意一个类，都能够知道这个类的所有属性和方法；对于任意一个对象，都能够调用它的任意一个方法和属性；这种动态获取的信息以及动态调用对象的方法的功能称为Java语言的反射机制。 反射机制获取类有三种方法123456789101112//1 直接通过类名.Class的方式得到 clazz = Person.class; System.out.println(\"通过类名: \" + clazz); //2 通过对象的getClass()方法获取,这个使用的少（一般是传的是Object，不知道是什么类型的时候才用） Object obj = new Person(); clazz = obj.getClass(); System.out.println(\"通过getClass(): \" + clazz); //3 通过全类名获取，用的比较多，但可能抛出ClassNotFoundException异常 clazz = Class.forName(\"com.java.reflection.Person\"); System.out.println(\"通过全类名获取: \" + clazz); 什么是数据库ACID? ACID，指数据库事务正确执行的四个基本要素的缩写。包含：原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）。 一个支持事务（Transaction）的数据库，必须要具有这四种特性，否则在事务过程（Transaction processing）当中无法保证数据的正确性，交易过程极可能达不到交易方的要求。 Atomic（原子性）：指整个数据库事务是不可分割的工作单位。只有使据库中所有的操作执行成功，才算整个事务成功；事务中任何一个SQL语句执行失败，那么已经执行成功的SQL语句也必须撤销，数据库状态应该退回到执行事务前的状态。 Consistency（一致性）：指数据库事务不能破坏关系数据的完整性以及业务逻辑上的一致性。例如对银行转帐事务，不管事务成功还是失败，应该保证事务结束后ACCOUNTS表中Tom和Jack的存款总额为2000元。 Isolation（隔离性）：指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。 Durability（持久性）：指的是只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。 BS与CS的联系与区别 C/S是Client/Server的缩写。服务器通常采用高性能的PC、工作站或小型机，并采用大型数据库系统，如Oracle、Sybase、InFORMix或 SQL Server。客户端需要安装专用的客户端软件。 B/Ｓ是Brower/Server的缩写，客户机上只要安装一个浏览器（Browser），如Netscape Navigator或Internet Explorer，服务器安装Oracle、Sybase、InFORMix或 SQL Server等数据库。在这种结构下，用户界面完全通过WWW浏览器实现，一部分事务逻辑在前端实现，但是主要事务逻辑在服务器端实现。浏览器通过Ｗeb Server同数据库进行数据交互。 C/S 与 B/S区别： １． 硬件环境不同: C/S 一般建立在专用的网络上,小范围里的网络环境,局域网之间再通过专门服务器提供连接和数据交换服务. B/S 建立在广域网之上的,不必是专门的网络硬件环境,例与电话上网,租用设备.信息自己管理.有比C/S更强的适应范围,一般只要有操作系统和浏览器就行 ２．对安全要求不同 C/S 一般面向相对固定的用户群,对信息安全的控制能力很强.一般高度机密的信息系统采用C/S结构适宜.可以通过B/S发布部分可公开信息. B/S 建立在广域网之上,对安全的控制能力相对弱,可能面向不可知的用户。 ３．对程序架构不同 C/S 程序可以更加注重流程,可以对权限多层次校验,对系统运行速度可以较少考虑. B/S 对安全以及访问速度的多重的考虑,建立在需要更加优化的基础之上.比C/S有更高的要求 B/S结构的程序架构是发展的趋势,从MS的.Net系列的BizTalk 2000Exchange 2000等,全面支持网络的构件搭建的系统. SUN和IBM推的JavaBean构件技术等,使 B/S更加成熟. ４．软件重用不同 C/S 程序可以不可避免的整体性考虑,构件的重用性不如在B/S要求下的构件的重用性好. B/S 对的多重结构,要求构件相对独立的功能.能够相对较好的重用.就入买来的餐桌可以再利用,而不是做在墙上的石头桌子 ５．系统维护不同 C/S 程序由于整体性,必须整体考察,处理出现的问题以及系统升级.升级难.可能是再做一个全新的系统 B/S 构件组成,方面构件个别的更换,实现系统的无缝升级.系统维护开销减到最小.用户从网上自己下载安装就可以实现升级. ６．处理问题不同 C/S 程序可以处理用户面固定,并且在相同区域,安全要求高需求,与操作系统相关.应该都是相同的系统 B/S 建立在广域网上,面向不同的用户群,分散地域,这是C/S无法作到的.与操作系统平台关系最小. ７．用户接口不同 C/S 多是建立的Window平台上,表现方法有限,对程序员普遍要求较高 B/S 建立在浏览器上,有更加丰富和生动的表现方式与用户交流.并且大部分难度减低,减低开发成本. ８．信息流不同 C/S 程序一般是典型的中央集权的机械式处理,交互性相对低 B/S 信息流向可变化, B-B B-C B-G等信息、流向的变化,更像交易中心。 cookie 和session 的区别?具体来说cookie机制采用的是在客户端保持状态的方案，而session机制采用的是在服务器端保持状态的方案。同时我们也看到，由于才服务器端保持状态的方案在客户端也需要保存一个标识，所以session机制可能需要借助于cookie机制来达到保存标识的目的，但实际上还有其他选择. 相同点：cookie与session都是用来跟踪浏览器用户身份的会话方式。 不同点：总的来说，cookie是采取的客户端保状态的会话方式，而session采取的是服务器保持状态的会话方式。 采用session的会话方式，用户量大时，因为数据保存在服务器，其服务器压力毫无疑问会比较大。还有其他的一些不同，如二者的存取方式等。 1、cookie数据存放在客户的浏览器上，session数据放在服务器上。 2、cookie不是很安全，别人可以分析存放在本地的COOKIE并进行COOKIE欺骗 考虑到安全应当使用session。 3、session会在一定时间内保存在服务器上。当访问增多，会比较占用你服务器的性能 考虑到减轻服务器性能方面，应当使用COOKIE。 4、单个cookie保存的数据不能超过4K，很多浏览器都限制一个站点最多保存20个cookie。 5、所以个人建议： 将登陆信息等重要信息存放为SESSION 其他信息如果需要保留，可以放在COOKIE中 fail-fast 与 fail-safe 机制有什么区别java中fail-fast 和 fail-safe的区别 在我们详细讨论这两种机制的区别之前，首先得先了解并发修改。 什么是同步修改？ 当一个或多个线程正在遍历一个集合Collection，此时另一个线程修改了这个集合的内容（添加，删除或者修改）。这就是并发修改 什么是 fail-fast 机制? fail-fast机制在遍历一个集合时，当集合结构被修改，会抛出Concurrent Modification Exception。 fail-fast会在以下两种情况下抛出ConcurrentModificationException （1）单线程环境 集合被创建后，在遍历它的过程中修改了结构。 注意 remove()方法会让expectModcount和modcount 相等，所以是不会抛出这个异常。 （2）多线程环境 当一个线程在遍历这个集合，而另一个线程对这个集合的结构进行了修改。 注意，迭代器的快速失败行为无法得到保证，因为一般来说，不可能对是否出现不同步并发修改做出任何硬性保证。快速失败迭代器会尽最大努力抛出 ConcurrentModificationException。因此，为提高这类迭代器的正确性而编写一个依赖于此异常的程序是错误的做法：迭代器的快速失败行为应该仅用于检测 bug。 fail-fast机制是如何检测的？ 迭代器在遍历过程中是直接访问内部数据的，因此内部的数据在遍历的过程中无法被修改。为了保证不被修改，迭代器内部维护了一个标记 “mode” ，当集合结构改变（添加删除或者修改），标记”mode”会被修改，而迭代器每次的hasNext()和next()方法都会检查该”mode”是否被改变，当检测到被修改时，抛出Concurrent Modification Exception fail-safe机制 fail-safe任何对集合结构的修改都会在一个复制的集合上进行修改，因此不会抛出ConcurrentModificationException fail-safe机制有两个问题 （1）需要复制集合，产生大量的无效对象，开销大 （2）无法保证读取的数据是目前原始数据结构中的数据。 Fail Fast Iterator Fail Safe Iterator Throw ConcurrentModification Exception Yes No Clone object No Yes Memory Overhead No Yes Examples HashMap,Vector,ArrayList,HashSet CopyOnWriteArrayList, ConcurrentHashMap get 和 post请求的区别 get 和 post请求的区别 GET - 从指定的资源请求数据。 POST - 向指定的资源提交要被处理的数据 GET 方法 请注意，查询字符串（名称/值对）是在 GET 请求的 URL 中发送的： 1/test/demo_form.asp?name1=value1&amp;name2=value2 有关 GET 请求的其他一些注释： GET 请求可被缓存 GET 请求保留在浏览器历史记录中 GET 请求可被收藏为书签 GET 请求不应在处理敏感数据时使用 GET 请求有长度限制 GET 请求只应当用于取回数据 POST 方法 请注意，查询字符串（名称/值对）是在 POST 请求的 HTTP 消息主体中发送的： 123POST /test/demo_form.asp HTTP/1.1Host: w3schools.comname1=value1&amp;name2=value2 有关 POST 请求的其他一些注释： POST 请求不会被缓存 POST 请求不会保留在浏览器历史记录中 POST 不能被收藏为书签 POST 请求对数据长度没有要求 GET POST 后退按钮/刷新 无害 数据会被重新提交（浏览器应该告知用户数据会被重新提交）。 缓存 能被缓存 不能缓存 编码类型 application/x-www-form-urlencoded application/x-www-form-urlencoded 或 multipart/form-data。为二进制数据使用多重编码。 历史 参数保留在浏览器历史中。 参数不会保存在浏览器历史中。 对数据长度的限制 是的。当发送数据时，GET 方法向 URL 添加数据；URL 的长度是受限制的（URL 的最大长度是 2048 个字符）。 无限制。 对数据类型的限制 只允许 ASCII 字符。 没有限制。也允许二进制数据。 安全性 与 POST 相比，GET 的安全性较差，因为所发送的数据是 URL 的一部分。在发送密码或其他敏感信息时绝不要使用 GET ！ POST 比 GET 更安全，因为参数不会被保存在浏览器历史或 web 服务器日志中。 可见性 数据在 URL 中对所有人都是可见的。 数据不会显示在 URL 中。 书签 可收藏为书签 不可收藏为书签 Interface与abstract类的区别 含有abstract修饰符的class即为抽象类，abstract 类不能创建的实例对象。含有abstract方法的类必须定义为abstract class，abstract class类中的方法不必是抽象的。abstract class类中定义抽象方法必须在具体(Concrete)子类中实现，所以，不能有抽象构造方法或抽象静态方法。如果的子类没有实现抽象父类中的所有抽象方法，那么子类也必须定义为abstract类型。 接口（interface）可以说成是抽象类的一种特例，接口中的所有方法都必须是抽象的。接口中的方法定义默认为public abstract类型，接口中的成员变量类型默认为public static final。 下面比较一下两者的语法区别： 抽象类可以有构造方法，接口中不能有构造方法。 抽象类中可以有普通成员变量，接口中没有普通成员变量 抽象类中可以包含非抽象的普通方法，接口中的所有方法必须都是抽象的，不能有非抽象的普通方法。 抽象类中的抽象方法的访问类型可以是public，protected和（默认类型,虽然 eclipse下不报错，但应该也不行），但接口中的抽象方法只能是public类型的，并且默认即为public abstract类型。 抽象类中可以包含静态方法，接口中不能包含静态方法 抽象类和接口中都可以包含静态成员变量，抽象类中的静态成员变量的访问类型可以任意，但接口中定义的变量只能是public static final类型，并且默认即为public static final类型。 一个类可以实现多个接口，但只能继承一个抽象类。 下面接着再说说两者在应用上的区别： 接口更多的是在系统架构设计方法发挥作用，主要用于定义模块之间的通信契约。而抽象类在代码实现方面发挥作用，可以实现代码的重用，例如，模板方法设计模式是抽象类的一个典型应用，假设某个项目的所有Servlet类都要用相同的方式进行权限判断、记录访问日志和处理异常，那么就可以定义一个抽象的基类，让所有的Servlet都继承这个抽象基类，在抽象基类的service方法中完成权限判断、记录访问日志和处理异常的代码，在各个子类中只是完成各自的业务逻辑代码。 WEB容器主要有哪些功能? 并请列出一些常见的WEB容器名字。 1) 提供Servlet程序编写API 2) 提供Servlet程序运行时环境。 常见的有 Apache, IIS, Tomcat, Resin 等等 一个”.java”源文件中是否可以包含多个类（不是内部类）？有什么限制？可以，但一个源文件中最多只能有一个公开类（public class）而且文件名必须和公开类的类名完全保持一致。 请简述 Servlet 的生命周期及其相关的方法 创建Servlet对象，通过服务器反射机制创建Servlet对象，第一次请 求时才会创建。（默认） 调用Servlet对象的init()方法，初始化Servlet的信息，init()方法只会在创建后被调用一次； 响应请求，调用service()或者是doGet()，doPost()方法来处理请求，这些方法是运行的在多线程状态下的。 在长时间没有被调用或者是服务器关闭时，会调用destroy()方法来销毁Servlet对象。 简述ajax的原理及实现步骤。HTTP协议的异步通信 Ajax的原理简单来说通过XmlHttpRequest对象来向服务器发异步请求，从服务器获得数据，然后用javascript来操作DOM而更新页面。这其中最关键的一步就是页面的部分从服务器获得请求数据。实现方式就利用页面部分刷新数据来给用户更好的体验。其中 XMLHttpRequest 是ajax的核心机制，Ajax本身是很多技术的集合，里面有很多要说的，自己可以从一些ajax的实例学习下。 什么是finalize()方法类的finalize()方法，可以告诉垃圾回收器应该执行的操作，该方法从Object类继承而来。在从堆中永久删除对象之前，垃圾回收器调用该对象的finalize()方法。注意，无法确切地保证垃圾回收器何时调用该方法，也无法保证调用不同对象的方法的顺序。即使一个对象包含另一个对象的引用，或者在释放一个对象很久以前就释放了另一个对象，也可能会以任意的顺序调用这两个对象的Finalize方法。如果必须保证采用特定的顺序，则必须提供自己的特有清理方法。finalize()一般是用不到的，除非JVM认为已经没有内存可以使用了，那时JVM才会消耗资源去清理垃圾，所以finalize()也不能作为通用的清理方法。而且finalize()有一个比较另类的用法，就是说finalize()并不依赖对它的直接调用，它有某些触发机制，比如说对象已经标明要被终结，这时会自动执行finalize()。并不需要去显式的调用，这也是为什么代码中没有显式调用finalize()，但它确实执行了的原因，因为它触发了finalize()的执行条件。其实不必太在意finalize()，因为一般的程序中是使用不到finalize()的，所以那些开发Java的大牛们把finalize()的用法整的很隐晦，而且它们把垃圾回收机制做的比较自动化，一般不需要手工清理。 final关键字有哪些用法 用来修饰数据，包括成员变量和局部变量，该变量只能被赋值一次且它的值无法被改变。对于成员变量来讲，我们必须在声明时或者构造方法中对它赋值； 用来修饰方法参数，表示在变量的生存期中它的值不能被改变； 修饰方法，表示该方法无法被重写； 修饰类，表示该类无法被继承。 上面的四种方法中，第三种和第四种方法需要谨慎使用，因为在大多数情况下，如果是仅仅为了一点设计上的考虑，我们并不需要使用final来修饰方法和类。 main() 方法为什么必须是静态的？能不能声明 main() 方法为非静态?不能，main()方法必须声明为静态的，这样JVM才可以调用main()方法而无需实例化它的类。 如果从main()方法去掉“static”这个声明，虽然编译依然可以成功，但在运行时会导致程序失败。 如果JVM找不到main方法就抛出NoSuchMethodError:main异常，例如：如果你运行命令：java HelloWrold，JVM就会在HelloWorld.class文件中搜索public static void main (String[] args) 放法 main方式是程序的入口，程序执行的开始处。 main方法被一个特定的线程”main”运行，程序会一直运行直到main线程结束或者non-daemon线程终止。 当你看到“Exception in Thread main”如：Excpetion in Thread main:Java.lang.NullPointedException ,意味着异常来自于main线程 你可以声明main方法使用java1.5的可变参数的方式如： public static void main(String… args) 除了static、void、和public，你可以使用final，synchronized、和strictfp修饰符在main方法的签名中，如： public strictfp final synchronized static void main(String[] args) main方法在Java可以像其他方法一样被重载，但是JVM只会调用上面这种签名规范的main方法。 你可以使用throws子句在方法签名中，可以抛出任何checked和unchecked异常 静态初始化块在JVM调用main方法前被执行，它们在类被JVM加载到内存的时候就被执行了。 a = a + b 与 a += b 的区别123a+=b --&gt; a=(a.Type)a+b;//返回的是a类型 a=a+b --&gt; a=a+b;//返回类型是a类型与b类型中的最高类型 如果有这样的代码:short a = a + 1;这句编译时会报错,因为a+1以后,类型强制转换为int,这是在赋值给short类型的a就错了,但是short a=1; a+=1;就不会报错 3*0.1 == 0.3 将会返回什么？true 还是 false？false,有些浮点数不能完全精确的表示出来。为了解决基本数据类型浮点数不能进行精确计算的问题，Java中专门提供了java.math.BigDecimal类，其提供浮点数的精确计算功能。与BigInteger类相同，其运算操作均使用方法调用完成 基础类型(Primitives)与封装类型(Wrappers)的区别一、传递方式不同基本类型（原始数据类型）在传递参数时都是按值传递，而封装类型是按引用传递的(其实“引用也是按值传递的”，传递的是对象的地址)。由于包装类型都是不可变量，因此没有提供改变它值的方法，增加了对“按引用传递”的理解难度。 int是基本类型，直接存放数值；Integer是类，产生对象时用一个引用指向这个对象。 二、封装类可以有方法和属性封装类可以有方法和属性，利用这些方法和属性来处理数据，如Integer.parseInt(Strings)。基本数据类型都是final修饰的，不能继承扩展新的类、新的方法。 三、默认值不同基本类型跟封装类型的默认值是不一样的。如int i,i的预设为0；Integer j，j的预设为null,因为封装类产生的是对象，对象默认值为null。 四、存储位置基本类型在内存中是存储在栈中，引用类型的引用（值的地址）存储在栈中，而实际的对象（值）是存在堆中。 虽然基本类型在栈上分配内存效率高，但是在堆栈上分配内存可能有内存泄漏的问题。 float和double的默认值是多少单精度浮点型（float）的基本类型变量的默认值为0.0f； 双精度浮点型（double）的基本类型变量的默认值为0.0d； 我能在不进行强制转换的情况下将一个 double 值赋值给 long 类型的变量吗？ 不行，你不能在没有强制类型转换的前提下将一个 double 值赋值给 long 类型的变量，因为 double 类型的范围比 long 类型更广，所以必须要进行强制转换。 继承中类型转换的两种方式（向上转型、向下转型）继承中类型转换的两种方式 1.向上转型 将子类对象转换成父类类型，例如： Pet pet=new Dog(); 此类型转换为自动转换 因为子类的功能比父类更加强大，相当于让一个能力强的对象去做一件简单的事情，因此可以自动转换完成 2.向下转型 将父类对象转换为子类类型，例如： Pet pet=new Pet(); Dog dog=(Dog)pet; 此类型转换为强制转换 因为反之，父类的功能要弱于子类，因此需要强制转换 如何权衡是使用无序的数组还是有序的数组 有序数组最大的好处：在于查找的时间复杂度是O(log n)，而无序数组是O(n)。 有序数组的缺点是：插入操作的时间复杂度是O(n)，因为值大的元素需要往后移动来给新元素腾位置。相反，无序数组的插入时间复杂度是常量O(1)。 怎么判断数组是 null 还是为空长度为0的数组，可以求数组长度，为0，即数组内没有元素。 1int[] zero = new int[0]; //zero引用一个长度为0的数组对象1 为null的数组，不能求数组长度，且求解时会出现空指针异常NullPointerException。 1int[] zero = null; //数组类型的空引用，不指向任何对象 Java数组的三种打印方式123456789//传统的for循环方式for(int i=0;i&lt;array.length;i++) System.out.println(a[i]);//for each循环for(int a:array) System.out.println(a);//利用Array类中的toString方法int[] array = &#123;1,2,3,4,5&#125;;System.out.println(Arrays.toString(array));","tags":[{"name":"面试题","slug":"面试题","permalink":"https://imnice.github.io/tags/面试题/"}]},{"title":"数组整体右移K位问题","date":"2018-09-18T04:08:42.000Z","path":"2018/09/18/数组整体右移K位问题/","text":"问题： 如何把一个数组循环右移K位 如：12345678 右移2位 78123456 思路一：写一个方法，让数组右移一位，要求右移几位就调用多少次 思路二：我们先将数组分成两部分, 设后面K位为数组b, 前面length()-K位为数组a, 那么怎么数组的组成就是ab.原始数组是ab, 我的目的是将这个数组变成ba 第一步:将整个长度为N的数组倒置得到$b^{-1}$ $a^{-1}$ 第二步:将$b^{-1}$数组和$a^{-1}$ 数组分别倒置, 得到 ba数组. 具体代码如下 123456789101112131415161718192021222324252627282930313233343536373839404142434445import java.util.Arrays;public class ShuZuYouYi &#123; public static void main(String[] args) &#123; int[] nums = new int[] &#123; 1, 2, 3, 4, 5, 6, 7, 8 &#125;; int k = 2;// 需要右移的位数 System.out.println(Arrays.toString(nums)); // 方法一：暴力循环调用右移一次的函数 for (int i = 0; i &lt; k; i++) &#123; youYiOnce(nums); &#125; System.out.println(Arrays.toString(nums)); // 方法二： //将整个长度为N的数组倒置得到b^&#123;-1&#125;a^&#123;-1&#125; reverse(nums, 0, nums.length - 1); //将b^&#123;-1&#125;数组和a^&#123;-1&#125; 数组分别倒置, 得到 ba数组. reverse(nums, 0, k - 1); reverse(nums, k, nums.length - 1); System.out.println(Arrays.toString(nums)); &#125; //右移一次的函数 public static void youYiOnce(int[] nums) &#123; int last = nums[nums.length - 1]; for (int i = nums.length - 2; i &gt;= 0; i--) &#123; nums[i + 1] = nums[i]; &#125; nums[0] = last; &#125; //转置数组的第start到end位 public static void reverse(int[] nums, int start, int end) &#123; for (int i = start; i &lt;= end; i++) &#123; int temp = nums[start]; nums[start] = nums[end]; nums[end] = temp; start++; end--; &#125; &#125;&#125;","tags":[{"name":"面试题","slug":"面试题","permalink":"https://imnice.github.io/tags/面试题/"},{"name":"算法","slug":"算法","permalink":"https://imnice.github.io/tags/算法/"}]},{"title":"Java计算两个日期相隔的天数","date":"2018-09-18T02:08:42.000Z","path":"2018/09/18/Java计算两个日期相隔的天数/","text":"最近遇到了一个问题，如何计算给定两个日期之间隔了多少天，这在平时的项目和面试中也比较常见，总结一发。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869import java.text.ParseException;import java.text.SimpleDateFormat;import java.util.Calendar;import java.util.Date;//判断两个日期之间相隔的天数public class DayCount &#123; public static void main(String[] args) throws ParseException &#123; SimpleDateFormat format = new SimpleDateFormat(\"yyyy-MM-dd\"); Date date1 = format.parse(\"1999-09-09\"); Date date2 = format.parse(\"2011-11-11\"); System.out.println(differentDays(date1, date2));//4446 System.out.println(differentDaysByMillisecond(date1, date2));//4446 System.out.println(differentDaysByCalendar(date1, date2));//4446 &#125; /** * date2比date1多的天数 */ public static int differentDays(Date date1, Date date2) &#123; Calendar cal1 = Calendar.getInstance(); cal1.setTime(date1); Calendar cal2 = Calendar.getInstance(); cal2.setTime(date2); int day1 = cal1.get(Calendar.DAY_OF_YEAR);// 这一天是一年中的第几天 int day2 = cal2.get(Calendar.DAY_OF_YEAR); int year1 = cal1.get(Calendar.YEAR); int year2 = cal2.get(Calendar.YEAR); if (year1 != year2) &#123; int timeDistance = 0; for (int i = year1; i &lt; year2; i++) &#123; if (i % 4 == 0 &amp;&amp; i % 100 != 0 || i % 400 == 0) // 闰年 &#123; timeDistance += 366; &#125; else // 不是闰年 &#123; timeDistance += 365; &#125; &#125; return timeDistance + (day2 - day1); &#125; else &#123; System.out.println(\"判断day2 - day1 : \" + (day2 - day1)); return day2 - day1; &#125; &#125; /** * 通过时间秒毫秒数判断两个时间的间隔 */ public static int differentDaysByMillisecond(Date date1, Date date2) &#123; int days = (int) ((date2.getTime() - date1.getTime()) / (1000 * 3600 * 24)); return days; &#125; public static int differentDaysByCalendar(Date date1, Date date2) throws ParseException &#123; Calendar calendar = Calendar.getInstance(); calendar.setTime(date1); int cnt = 0; while (calendar.getTime().compareTo(date2) != 0) &#123; calendar.add(Calendar.DATE, 1);//calendar.add(*,-1)即是减去。calendar没有减法 cnt++; &#125; return cnt; &#125;&#125;","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://imnice.github.io/tags/Java基础/"},{"name":"日期计算","slug":"日期计算","permalink":"https://imnice.github.io/tags/日期计算/"}]},{"title":"Java基础面试题（一）","date":"2018-09-17T07:08:42.000Z","path":"2018/09/17/Java基础面试题（一）/","text":"Java基础面试题（一） Java基本类型占用的字节数：1字节： byte , boolean2字节： short , char4字节： int , float8字节： long , double注：1字节(byte)=8位(bits) 在Java语言中，字符串”Java程序员”在内存中所占用的字节数是：（D）。 A. 10 B. 7 C. 13 D. 14int与integer的对比？ Integer是int的包装类；int是基本数据类型； Integer变量必须实例化后才能使用；int变量不需要； Integer实际是对象的引用，指向此new的Integer对象；int是直接存储数据值 ； Integer的默认值是null；int的默认值是0。注意：integer类中的内部类，是处理Integer的缓存，cache的大小为256，static块中是对cache赋值从-128(包含)~127(包含)，所以上面的例子可以得出100在范围以内不会产生新的对象，直接返回缓存中的对象，200不在范围内会产生新的对象，注意Integer的缓存数据是不会被垃圾回收。能将 int 强制转换为 byte类型的变量吗？如果该值大于byte类型的范围，将会出现什么现象？我们可以做强制转换，但是 Java 中 int 是 32 位的，而 byte 是 8 位的，所以，如果强制转化，int 类型的高 24 位将会被丢弃，因为byte 类型的范围是从 -128到127。一个”.java”源文件中是否可以包括多个类（不是内部类）？有什么限制？可以有多个类，但只能有一个public的类，并且public的类名必须与文件名相一致。在JAVA中如何跳出当前的多重嵌套循环？ 在Java中，要想跳出多重循环，可以在外面的循环语句前定义一个标号，然后在里层循环体的代码中使用带有标号的break语句，即可跳出外层循环。例如： 1234567ok: for (int i = 0; i &lt; 10; i++) &#123; for (int j = 0; j &lt; 10; j++) &#123; System.out.println(\"i=\" + i + \",j=\" + j); if (j == 5) break ok; &#125;&#125; 另外，通常并不使用标号这种方式，而是让外层的循环条件表达式的结果可以受到里层循环体代码的控制，例如，要在二维数组中查找到某个数字。 1234567891011int arr[][] = &#123; &#123; 1, 2, 3 &#125;, &#123; 4, 5, 6, 7 &#125;, &#123; 9 &#125; &#125;;boolean found = false;for (int i = 0; i &lt; arr.length &amp;&amp; !found; i++) &#123; for (int j = 0; j &lt; arr[i].length; j++) &#123; System.out.println(\"i=\" + i + \",j=\" + j); if (arr[i][j] == 5) &#123; found = true; break; &#125; &#125;&#125; switch语句能否作用在byte上，能否作用在long上，能否作用在String上?在switch（e）中，e只能是一个整数表达式或者枚举常量（Java1.7以后支持String），整数表达式可以是int基本类型或Integer包装类型，由于byte,short,char都可以隐含转换为int，（String和enum也可以用在switch语句上）所以，这些类型以及这些类型的包装类型也是可以的。显然，long不符合switch的语法规定，并且不能被隐式转换成int类型，所以，它们不能作用于swtich语句中。注意：switch在没有break的情况下会依次执行后面所有的case！！！ short s1= 1; s1 = s1+1；有什么错? short s1 = 1; s1 += 1;有什么错?(没有错)对于short s1 = 1; s1 = s1 + 1;由于s1+1 运算时会自动提升表达式的类型，所以结果是int型，再赋值给short类型s1时，编译器将报告需要强制转换类型的错误。对于short s1= 1; s1 += 1;由于 += 是java语言规定的运算符，java编译器会对它进行特殊处理，因此可以正确编译。注意：s1++；也是可以通过编译的！ 使用final关键字修饰一个变量时，是引用不能变，还是引用的对象不能变？使用final关键字修饰一个变量时，是指引用变量不能变，引用变量所指向的对象中的内容还是可以改变的。例如，对于如下语句： final StringBuffer a=new StringBuffer(“immutable”); 执行如下语句将报告编译期错误： a=new StringBuffer(“”); 但是，执行如下语句则可以通过编译： a.append(“ broken!”); 是否可以从一个static方法内部发出对非static方法的调用？不可以。因为非static方法是要与对象关联在一起的，必须创建一个对象后，才可以在该对象上进行方法调用，而static方法调用时不需要创建对象，可以直接调用。也就是说，当一个static方法被调用时，可能还没有创建任何实例对象，如果从一个static方法中发出对非static方法的调用，那个非static方法是关联到哪个对象上的呢？这个逻辑无法成立，所以，一个static方法内部发出对非static方法的调用。注意：Java类的加载顺序一般是：父类的静态变量（静态代码块）—&gt;子类的静态变量（静态代码块）—&gt;父类的构造方法—&gt;子类的构造方法。 Math类中提供了三个与取整有关的方法：ceil、floor、round怎么使用？ Math.ceil()表示向上取整 Math.ceil(1.1)结果是2，Math.ceil(-1.1)结果是-1。 Math.floor()表示向下取整 Math.floor(1.1)结果是1，Math.floor(-1.1)结果是-2。 Math.round()表示四舍五入取整 Math.round(1.1)结果是1，Math.round(-1.5)结果是-1。 注意：四舍五入的原理是在参数上加 0.5然后进行向下取整。 Overload和Override的区别？ Overload Override 中文名 重载 重写/覆盖 发生范围 一个类中 父类与子类之间 方法的参数 参数个数，类型，顺序至少有一个不相同 参数个数，类型，顺序都是必须和父 类方法一致的 方法返回值 返回值可以同或者不同（不能重载只有返回值不同的方法名） 返回值必须相同 final修饰 可以重载 不可以重写 异常 方法的异常类型和数目不会对重载造成影响 子类方法不能抛出比父类方法更多的异常(但子类方法可以不抛出异常) 注意：被覆盖的方法不能为private，否则在其子类中只是新定义了一个方法，并没有对其进行覆盖。 接口是否可继承接口?抽象类是否可实现(implements)接口?抽象类是否可继承具体类(concreteclass)?抽象类中是否可以有静态的main方法？接口可以继承接口。抽象类可以实现(implements)接口，抽象类可以继承具体类。抽象类中可以有静态的main方法。注意：抽象类与普通类的唯一区别就是不能创建实例对象和允许有abstract方法。 抽象类和接口语法上有什么区别? 抽象类可以有构造方法，接口中不能有构造方法。 抽象类中可以有普通成员变量，接口中没有普通成员变量（必须是public static final修饰）。 抽象类中可以包含非抽象的普通方法，接口中的所有方法必须都是抽象的，不能有非抽象的普通方法。 抽象类中的抽象方法的访问类型可以是public，protected和（默认类型,虽然eclipse下不报错，但应该也不行），但接口中的抽象方法只能是public类型的，并且默认即为public abstract类型。 抽象类中可以包含静态方法，接口中不能包含静态方法。 抽象类和接口中都可以包含静态成员变量，抽象类中的静态成员变量的访问类型可以任意，但接口中定义的变量只能是public static final类型，并且默认即为public static final类型。 一个类可以实现多个接口，但只能继承一个抽象类。Java中实现多态的机制是什么？靠的是父类或接口定义的引用变量可以指向子类或具体实现类的实例对象，而程序调用的方法在运行期才动态绑定，就是引用变量所指向的具体实例对象的方法，也就是内存里正在运行的那个对象的方法，而不是引用变量的类型中定义的方法。 new 一个对象的过程和 clone 一个对象的过程区别？new 操作符的本意是分配内存。程序执行到 new 操作符时，首先去看 new 操作符后面的类型，因为知道了类型，才能知道要分配多大的内存空间。分配完内存之后，再调用构造函数，填充对象的各个域，这一步叫做对象的初始化，构造方法返回后，一个对象创建完毕，可以把他的引用（地址）发布到外部，在外部就可以使用这个引用操纵这个对象。clone 在第一步是和 new 相似的，都是分配内存，调用 clone 方法时，分配的内存和原对象（即调用 clone 方法的对象）相同，然后再使用原对象中对应的各个域，填充新对象的域，填充完成之后， clone 方法返回，一个新的相同的对象被创建，同样可以把这个新对象的引用发布到外部。 什么是深拷贝什么是浅拷贝？Person 中有两个成员变量，分别是 name 和 age， name 是 String 类型， age 是 int 类型。代码非常简单，如下所示： 12345678910111213141516171819202122232425public class Person implements Cloneable &#123; private int age; private String name; public Person(int age, String name) &#123; this.age = age; this.name = name; &#125; public Person() &#123; &#125; public int getAge() &#123; return age; &#125; public String getName() &#123; return name; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return (Person) super.clone(); &#125;&#125; 由于 age 是基本数据类型， 那么对它的拷贝没有什么疑议，直接将一个 4 字节的整数值拷贝过来就行。但是 name是 String 类型的， 它只是一个引用， 指向一个真正的 String 对象，那么对它的拷贝有两种方式： 直接将原对象中的 name 的引用值拷贝给新对象的 name 字段， 或者是根据原 Person 对象中的 name 指向的字符串对象创建一个新的相同的字符串对象，将这个新字符串对象的引用赋给新拷贝的 Person 对象的 name 字段。这两种拷贝方式分别叫做浅拷贝和深拷贝。深拷贝和浅拷贝的原理如下图所示： 如何进行深拷贝？ 由上一节的内容可以得出如下结论：如果想要深拷贝一个对象，这个对象必须要实现 Cloneable 接口，实现 clone方法，并且在 clone 方法内部，把该对象引用的其他对象也要 clone 一份，这就要求这个被引用的对象必须也要实现Cloneable 接口并且实现 clone 方法。那么，按照上面的结论，实现以下代码 Body 类组合了 Head 类，要想深拷贝Body 类，必须在 Body 类的 clone 方法中将 Head 类也要拷贝一份。代码如下： 123456789101112131415161718public class Head implements Cloneable &#123; public Face face; public Head() &#123; &#125; @Override protected Object clone() throws CloneNotSupportedException &#123; return super.clone(); &#125; public static void main(String[] args) throws CloneNotSupportedException &#123; Body body = new Body(new Head(new Face())); Body body1 = (Body) body.clone(); System.out.println(\"body == body1 : \" + (body == body1)); System.out.println(\"body.head == body1.head : \" + (body.head == body1.head)); &#125;&#125; 打印结果为： body == body1 : false body.head == body1.head : false","tags":[{"name":"面试题","slug":"面试题","permalink":"https://imnice.github.io/tags/面试题/"}]},{"title":"Java常见的数字转换","date":"2018-09-13T04:08:42.000Z","path":"2018/09/13/Java常见的数字转换/","text":"Java常见的数字转换 int与String的互相转换int转String123456int i = 0;String string = new String();string = String.valueOf(i);string = i + \"\";string = Integer.toBinaryString(i); String转int12345String string = new String(\"12345\");int i = 0;i = Integer.valueOf(string);i = Integer.parseInt(string); 进制转换把10进制底下的数字1011，转换为2，8，16进制1234567System.out.println(\"把十进制的101，转化成2,8,16进制。\");System.out.println(Integer.toBinaryString(1011));// 转换成二进制1111110011System.out.println(Integer.toOctalString(1011));// 转换成八进制1763System.out.println(Integer.toHexString(1011));// 转换成十六进制3f3//把十进制转换成任意进制 例：10进制1011转成7进制2643System.out.println(Integer.toString(1011, 7));转换成七进制2643 把2，8，16进制底下的101，转换成10进制12345System.out.println(\"把2，8，16进制底下的1011，转换成10进制\");//此方法可以把任意进制都可以转换成十进制（十六进制英文字母大小写皆可）System.out.println(Integer.parseInt(\"1011\",2));// 二进制转换成十进制11System.out.println(Integer.parseInt(\"1011\",8));// 八进制转换成十进制521System.out.println(Integer.parseInt(\"1011\",16));// 十六进制转换成十进制4113 浮点型保留两位小数显示1234567double pi = 3.141592653589793;// 3.14System.out.println(((double) Math.round(pi * 100) / 100)); // 如果要精确到4位就是 *10000/10000System.out.println(String.format(\"%.2f\", pi)); // %表示小数点前任意位数2表示两位小数f表示浮点型DecimalFormat decimalFormat = new DecimalFormat(\".00\");// 如果小数点后不足两位会自动补0 ，写成\".##\"则不会System.out.println(decimalFormat.format(pi)); int和char的互相转换1234567891011int n = 1;char ch = (char) (n + '0');String strnum=n+\"\";char[] chars=strnum.toCharArray();chars[0];//////////////////////////////////char ch = '9';int n = ch - '0';int m = Integer.parseInt(String.valueOf(ch));","tags":[{"name":"Java基础","slug":"Java基础","permalink":"https://imnice.github.io/tags/Java基础/"}]},{"title":"Java常见的设计模式","date":"2018-09-12T07:08:42.000Z","path":"2018/09/12/Java常见的设计模式/","text":"Java 中一般认为有 23 种设计模式，我们不需要所有的都会，但是其中常用的几种设计模式应该去掌握。下面列出了所有的设计模式。 总体来说设计模式分为三大类： 创建型模式，共五种： 工厂方法模式、 抽象工厂模式、 单例模式、 建造者模式、原型模式。 结构型模式，共七种： 适配器模式、装饰器模式、 代理模式、外观模式、桥接模式、组合模式、 享元模式。 行为型模式，共十一种： 策略模式、模板方法模式、 观察者模式、迭代子模式、责任链模式、命令模式、备忘录模 式、状态模式、访问者模式、中介者模式、解释器模式。 单例模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950//饿汉模式public class Singleton1 &#123; // 直接创建对象 public static Singleton1 instance = new Singleton1(); // 私有化构造函数 private Singleton1() &#123; &#125; // 返回对象实例 public static Singleton1 getInstance() &#123; return instance; &#125;&#125;//懒汉模式public class Singleton2 &#123; // 声明变量 private static volatile Singleton2 singleton = null; // 私有构造函数 private Singleton2() &#123; &#125; // 提供对外方法 public static Singleton2 getInstance() &#123; if (singleton == null) &#123; singleton = new Singleton2(); &#125; return singleton; &#125;&#125;//注意，这不是线程安全的，有可能会问线程安全相关//双重检验锁模式（double checked locking pattern，DCL）public class Singleton3 &#123; private volatile static Singleton instance; //声明成 volatile private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (instance == null) &#123; synchronized (Singleton.class) &#123; if (instance == null) &#123; instance = new Singleton(); &#125; &#125; &#125; return instance; &#125;&#125; 工厂模式123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package my.factory;public interface Transportation &#123; public void tansprot();&#125;package my.factory;public class Car implements Transportation &#123; @Override public void tansprot() &#123; System.out.println(\"小汽车带你飞\"); &#125;&#125;package my.factory;public class Ship implements Transportation &#123; @Override public void tansprot() &#123; System.out.println(\"小轮船带你游！\"); &#125;&#125;package my.factory;//普通工厂模式public class TransportationFactory &#123; public Transportation transportationMaker(String type) &#123; if (\"Car\".equals(type)) &#123; return new Car(); &#125; else if (\"Ship\".equals(type)) &#123; return new Ship(); &#125; else &#123; return null; &#125; &#125;&#125;package my.factory;//多个工厂方法模式public class TransportationFactory2 &#123; public Transportation carFactory() &#123; return new Car(); &#125; public Transportation shipFactory() &#123; return new Ship(); &#125;&#125;package my.factory;//静态工厂模式public class TransportationFactory3 &#123; public static Transportation carFactory() &#123; return new Car(); &#125; public static Transportation shipFactory() &#123; return new Ship(); &#125;&#125;//还有抽象工厂模式。工厂方法模式有一个问题就是，类的创建依赖工厂类，也就是说，如果想要拓展程序，必须对工厂类进行修改，这违背了闭包原则，所以，从设计角度考虑，有一定的问题，如何解决？就用到抽象工厂模式，创建多个工厂类，这样一旦需要增加新的功能， 直接增加新的工厂类就可以了，不需要修改之前的代码。 代理模式1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495package my.proxy;public interface Travel &#123; public void ToTurkey();&#125;package my.proxy;public class Car implements Travel &#123; @Override public void ToTurkey() &#123; System.out.println(\"我开着小汽车带你去浪漫的土耳其！\"); &#125;&#125;package my.proxy;public class Ship implements Travel &#123; @Override public void ToTurkey() &#123; System.out.println(\"我开着泰坦尼克号带你到浪漫的土耳其！\"); &#125;&#125;package my.proxy;//静态代理，缺点是每个类都需要一个代理public class LandProxy implements Travel &#123; Car c = new Car(); @Override public void ToTurkey() &#123; c.ToTurkey(); &#125;&#125;package my.proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;//动态代理。public class NBProxy implements InvocationHandler &#123; private Object tar; //绑定委托对象，并返回代理类 public Object bind(Object tar) &#123; this.tar = tar; //绑定该类实现的所有接口，取得代理类 return Proxy.newProxyInstance(tar.getClass().getClassLoader(), tar.getClass().getInterfaces(), this); &#125; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //这里就可以进行所谓的AOP编程了 //在调用具体函数方法前，执行功能处理 Object result = method.invoke(tar, args); //在调用具体函数方法后，执行功能处理 return result; &#125;&#125;package my.proxy;public class TestProxy &#123; public static void main(String[] args) &#123; //测试静态代理 LandProxy land = new LandProxy(); land.ToTurkey(); //测试动态代理 NBProxy proxy = new NBProxy(); Travel t = (Travel) proxy.bind(new Ship()); t.ToTurkey(); &#125;&#125;//手写一个ArrayList的动态代理类package my.proxy;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;import java.util.ArrayList;import java.util.List;public class TestProxy &#123; public static void main(String[] args) &#123; // 手写一个list的动态代理 final List&lt;String&gt; list = new ArrayList&lt;String&gt;(); @SuppressWarnings(\"unchecked\") List&lt;String&gt; proxyInstance = (List&lt;String&gt;) Proxy.newProxyInstance(list.getClass().getClassLoader(), list.getClass().getInterfaces(), new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; return method.invoke(list, args); &#125; &#125;); proxyInstance.add(\"nihao\"); System.out.println(list); &#125;&#125;","tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://imnice.github.io/tags/设计模式/"}]},{"title":"排序算法盘点","date":"2018-09-10T10:00:50.000Z","path":"2018/09/10/排序算法大盘点/","text":"算法第一课一般都是从排序算法开始讲起的，现在来稍微盘点一下各种排序算法。 各种排序算法大比武 选择排序（Selection Sort）选择出数组中的最小元素，将它与数组的第一个元素交换位置。再从剩下的元素中选择出最小的元素，将它与数组的第二个元素交换位置。不断进行这样的操作，直到将整个数组排序。 代码实现 123456789101112131415161718public static void sort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; // 寻找[i, n)区间里的最小值的索引 int minIndex = i; for (int j = i + 1; j &lt; arr.length; j++) &#123; if(arr[minIndex] &gt; arr[j])&#123; minIndex = j; &#125; &#125; swap( arr , i , minIndex); &#125;&#125;private static void swap(int[] arr, int i, int j) &#123; int t = arr[i]; arr[i] = arr[j]; arr[j] = t;&#125; 算法分析 表现最稳定的排序算法之一，因为无论什么数据进去都是O(n2)的时间复杂度，所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。理论上讲，选择排序可能也是平时排序一般人想到的最多的排序方法了吧。 插入排序（Insertion Sort）插入排序从左到右进行，每次都将当前元素插入到左侧已经排序的数组中，使得插入之后左部数组依然有序。 第 j 元素是通过不断向左比较并交换来实现插入过程：当第 j 元素小于第 j - 1 元素，就将它们的位置交换，然后令 j 指针向左移动一个位置，不断进行以上操作。 代码实现 12345678910111213141516171819202122232425262728293031public static void sort(int[] arr) &#123; for (int i = 0; i &lt; arr.length - 1; i++) &#123; for (int j = i + 1; j &gt; 0; j--) &#123; if (arr[j] &lt; arr[j - 1]) swap(arr, j, j - 1); // 大量的交换会消耗时间 else break; &#125; &#125;&#125;// 改进版插入排序（减少了数组元素的操作次数）public static void better_sort(int[] arr) &#123; for (int i = 0; i &lt; arr.length; i++) &#123; int e = arr[i]; int j = i; for (; j &gt; 0; j--) &#123; if (e &lt; arr[j - 1]) arr[j] = arr[j - 1]; else break; &#125; arr[j] = e; &#125;&#125;private static void swap(int[] arr, int i, int j) &#123; int t = arr[i]; arr[i] = arr[j]; arr[j] = t;&#125; 算法分析 插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。 冒泡排序（Bubble Sort）通过从左到右不断交换相邻逆序的相邻元素，在一轮的交换之后，可以让未排序的元素上浮到右侧。 在一轮循环中，如果没有发生交换，就说明数组已经是有序的，此时可以直接退出。 代码实现 12345678910111213141516171819private static void sort(int[] arr) &#123; for (int i = arr.length - 1; i &gt; 0; i--) &#123; // 从最后一位开始确定 boolean swapped = false; for (int j = 0; j &lt; i; j++) &#123; if(arr[j] &gt; arr[j+1])&#123; swapped = true; swap(arr,j,j+1); &#125; &#125; if(!swapped) return; &#125;&#125;private static void swap(int[] arr, int i, int j) &#123; int t = arr[i]; arr[i] = arr[j]; arr[j] = t;&#125; 希尔排序（Shell Sort）1959年Shell发明，第一个突破O(n2)的排序算法，是简单插入排序的改进版。它与插入排序的不同之处在于，它会优先比较距离较远的元素。希尔排序又叫缩小增量排序。 算法描述 先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，具体算法描述： 选择一个增量序列t1，t2，…，tk，其中ti&gt;tj，tk=1； 按增量序列个数k，对序列进行k 趟排序； 每趟排序，根据对应的增量ti，将待排序列分割成若干长度为m 的子序列，分别对各子表进行直接插入排序。仅增量因子为1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 希尔排序public static void sort(int[] arr) &#123; int n = arr.length; for (int h = n / 2; h &gt; 0; h = h / 2) &#123; // 内部是一个插入排序 for (int i = 0; i &lt; n; i = i + h) &#123; int e = arr[i]; int j = i; for (; j &gt; 0; j = j - h) &#123; if (e &lt; arr[j - h]) arr[j] = arr[j - h]; else break; &#125; arr[j] = e; &#125; &#125;&#125;// 希尔排序2public static void sort2(int[] arr) &#123; int n = arr.length; // 计算 increment sequence: 1, 4, 13, 40, 121, 364, 1093... int h = 1; while (h &lt; n / 3) h = 3 * h + 1; System.out.println(h); while (h &gt;= 1) &#123; // h-sort the array for (int i = h; i &lt; n; i++) &#123; // 对 arr[i], arr[i-h], arr[i-2*h], arr[i-3*h]... 使用插入排序 int e = arr[i]; int j = i; for (; j &gt;= h &amp;&amp; e &lt; arr[j - h]; j -= h) arr[j] = arr[j - h]; arr[j] = e; &#125; h /= 3; &#125;&#125; 算法分析 对于大规模的数组，插入排序很慢，因为它只能交换相邻的元素，每次只能将逆序数量减少 1。 希尔排序的出现就是为了改进插入排序的这种局限性，它通过交换不相邻的元素，每次可以将逆序数量减少大于 1。 希尔排序使用插入排序对间隔 h 的序列进行排序。通过不断减小 h，最后令 h=1，就可以使得整个数组是有序的。 归并排序（Merge Sort）归并排序的思想是将数组分成两部分，分别进行排序，然后归并起来。把长度为n的输入序列分成两个长度为n/2的子序列；对这两个子序列分别采用归并排序；将两个排序好的子序列合并成一个最终的排序序列。 代码实现 1.归并方法 归并方法将数组中两个已经排序的部分归并成一个。 1234567891011121314151617181920212223242526272829303132333435private static void sort(int[] arr) &#123; __MergeSort(arr, 0, arr.length - 1);&#125;private static void __MergeSort(int[] arr, int l, int r) &#123; if (l &gt;= r) return; int mid = (l + r) / 2; __MergeSort(arr, l, mid); __MergeSort(arr, mid + 1, r); merge(arr, l, mid, r);&#125;// 将arr[l...mid]和arr[mid+1...r]两部分进行归并private static void merge(int[] arr, int l, int mid, int r) &#123; int[] aux = Arrays.copyOfRange(arr, l, r + 1); // 初始化，i指向左半部分的起始索引位置l；j指向右半部分起始索引位置mid+1 int i = l, j = mid + 1; for (int k = l; k &lt;= r; k++) &#123; if (i &gt; mid) &#123; // 如果左半部分元素已经全部处理完毕 arr[k] = aux[j - l]; j++; &#125; else if (j &gt; r) &#123; // 如果右半部分元素已经全部处理完毕 arr[k] = aux[i - l]; i++; &#125; else if (aux[i - l] &lt; aux[j - l]) &#123; // 左半部分所指元素 &lt; 右半部分所指元素 arr[k] = aux[i - l]; i++; &#125; else &#123; // 左半部分所指元素 &gt;= 右半部分所指元素 arr[k] = aux[j - l]; j++; &#125; &#125;&#125; 2.自底向上归并排序 1234567private static void sort(int[] arr) &#123; int N = arr.length; int[] aux = new int[N]; for (int sz = 1; sz &lt; N; sz += sz) for (int i = 0; i + sz &lt; N; i += sz + sz) merge(arr, i, i + sz - 1, Math.min(i + sz + sz - 1, N - 1));&#125; 快速排序（Quick Sort）快速排序可以说是20世纪最伟大的算法之一了。相信都有所耳闻，它的速度也正如它的名字那样，是一个非常快的算法了。当然它也后期经过了不断的改进和优化，才被公认为是一个值得信任的非常优秀的算法。 代码实现 1. 普通快速排序1234567891011121314151617181920212223242526272829303132// 递归使用快速排序,对arr[l...r]的范围进行排序public static void QuickSort(int[] arr,int l,int r)&#123; if(l&gt;=r) return; int p = partition(arr,l,r); QuickSort(arr,l,p-1); QuickSort(arr,p+1,r);&#125;// 将数组通过p分割成两部分// 对arr[l...r]部分进行partition操作// 返回p, 使得arr[l...p-1] &lt; arr[p] ; arr[p+1...r] &gt; arr[p]public static int partition(int[] arr, int l, int r) &#123; swap(arr, l, (int) (Math.random() % (r - l + 1)) + l); // 加入这一行变成随机快速排序 int v = arr[l]; int j = l; for(int i = j +1;i&lt;=r;i++)&#123; if(arr[i] &lt; v)&#123; j++; swap(arr,i,j); &#125; &#125; swap(arr,l,j); return j;&#125;public static void swap(int[] arr,int i,int j) &#123; int temp = arr[i]; arr[i] = arr[j]; arr[j] = temp;&#125; 快速排序是原地排序，不需要辅助数组，但是递归调用需要辅助栈。 快速排序最好的情况下是每次都正好能将数组对半分，这样递归调用次数才是最少的。这种情况下比较次数为 CN=2CN/2+N，复杂度为 O(NlogN)。 最坏的情况下，第一次从最小的元素切分，第二次从第二小的元素切分，如此这般。因此最坏的情况下需要比较 N2/2。为了防止数组最开始就是有序的，在进行快速排序时需要随机打乱数组。 2. 双路快速排序若果数组中含有大量重复的元素，则partition很可能把数组划分成两个及其不平衡的两部分，时间复杂度退化成O(n²)。这时候应该把小于v和大于v放在数组两端。 123456789101112131415161718192021222324252627282930313233343536373839404142434445// 双路快速排序的partition// 返回p, 使得arr[l...p-1] &lt; arr[p] ; arr[p+1...r] &gt; arr[p]private static int partition(int[] arr, int l, int r) &#123; // 随机在arr[l...r]的范围中, 选择一个数值作为标定点pivot // swap(arr, l, (int) (Math.random() % (r - l + 1)) + l); int v = arr[l]; // arr[l+1...i) &lt;= v; arr(j...r] &gt;= v int i = l + 1, j = r; while (true) &#123; // 注意这里的边界, arr[i].compareTo(v) &lt; 0, 不能是arr[i].compareTo(v) &lt;= 0 // 思考一下为什么? while (i &lt;= r &amp;&amp; arr[i] &lt; v) i++; // 注意这里的边界, arr[j].compareTo(v) &gt; 0, 不能是arr[j].compareTo(v) &gt;= 0 // 思考一下为什么? while (j &gt;= l + 1 &amp;&amp; arr[j] &gt; v) j--; // 对于上面的两个边界的设定, 有的同学在课程的问答区有很好的回答:) // 大家可以参考: http://coding.imooc.com/learn/questiondetail/4920.html if (i &gt; j) break; swap(arr, i, j); i++; j--; &#125; swap(arr, l, j); return j;&#125;// 递归使用快速排序,对arr[l...r]的范围进行排序private static void QuickSort2Ways(int[] arr, int l, int r) &#123; // 对于小规模数组, 使用插入排序 if (l &gt;= r) return; int p = partition(arr, l, r); QuickSort2Ways(arr, l, p - 1); QuickSort2Ways(arr, p + 1, r);&#125; 3. 三路快速排序数组分成三个部分，大于v 等于v 小于v 在具有大量重复键值对的情况下使用三路快排 123456789101112131415161718192021222324252627282930// 递归使用快速排序,对arr[l...r]的范围进行排序private static void QuickSort3Ways(int[] arr, int l, int r)&#123; // 随机在arr[l...r]的范围中, 选择一个数值作为标定点pivot swap( arr, l, (int)(Math.random()*(r-l+1)) + l ); int v = arr[l]; int lt = l; // arr[l+1...lt] &lt; v int gt = r + 1; // arr[gt...r] &gt; v int i = l+1; // arr[lt+1...i) == v while( i &lt; gt )&#123; if( arr[i] &lt; v)&#123; swap( arr, i, lt+1); i ++; lt ++; &#125; else if( arr[i] &gt; v )&#123; swap( arr, i, gt-1); gt --; &#125; else&#123; // arr[i] == v i ++; &#125; &#125; swap( arr, l, lt ); QuickSort3Ways(arr, l, lt-1); QuickSort3Ways(arr, gt, r);&#125; 堆排序（Heap Sort）1. 堆堆的某个节点的值总是大于等于子节点的值，并且堆是一颗完全二叉树。 堆可以用数组来表示，因为堆是完全二叉树，而完全二叉树很容易就存储在数组中。位置 k 的节点的父节点位置为 k/2，而它的两个子节点的位置分别为 2k 和 2k+1。这里不使用数组索引为 0 的位置，是为了更清晰地描述节点的位置关系。 2. 上浮和下沉在堆中，当一个节点比父节点大，那么需要交换这个两个节点。交换后还可能比它新的父节点大，因此需要不断地进行比较和交换操作，把这种操作称为上浮（ShiftUp）。 123456private void shiftUp(int k)&#123; while( k &gt; 1 &amp;&amp; data[k/2] &lt; data[k]))&#123; swap(k, k/2); k /= 2; &#125;&#125; 类似地，当一个节点比子节点来得小，也需要不断地向下进行比较和交换操作，把这种操作称为下沉（Shift Down）。一个节点如果有两个子节点，应当与两个子节点中最大那么节点进行交换。 12345678910111213private void shiftDown(int k)&#123; while( 2*k &lt;= count )&#123; // 当前结点有左孩子 int j = 2*k; // 在此轮循环中,data[k]和data[j]交换位置 if( j+1 &lt;= count &amp;&amp; data[j+1] &gt; data[j] ) j ++; // data[j] 是 data[2*k]和data[2*k+1]中的最大值 if( data[k] &gt;= data[j] ) break; swap(k, j); k = j; &#125;&#125; 3.插入元素将新元素放到数组末尾，然后上浮到合适的位置。 1234567// 向最大堆中插入一个新的元素 itempublic void insert(Item item)&#123; assert count + 1 &lt;= capacity; data[count+1] = item; count ++; shiftUp(count);&#125; 4. 删除最大元素12345678910// 从最大堆中取出堆顶元素, 即堆中所存储的最大数据public Item extractMax()&#123; assert count &gt; 0; Item ret = data[1]; swap( 1 , count ); count --; shiftDown(1); return ret;&#125; 5. 堆排序由于堆可以很容易得到最大的元素并删除它，不断地进行这种操作可以得到一个递减序列。如果把最大元素和当前堆中数组的最后一个元素交换位置，并且不删除它，那么就可以得到一个从尾到头的递减序列，从正向来看就是一个递增序列。因此很容易使用堆来进行排序。并且堆排序是原地排序，不占用额外空间。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283// 不使用一个额外的最大堆, 直接在原数组上进行原地的堆排序public class HeapSort &#123; // 对整个arr数组使用HeapSort1排序 // HeapSort1, 将所有的元素依次添加到堆中, 在将所有元素从堆中依次取出来, 即完成了排序 // 无论是创建堆的过程, 还是从堆中依次取出元素的过程, 时间复杂度均为O(nlogn) // 整个堆排序的整体时间复杂度为O(nlogn) public static void sort1(Comparable[] arr)&#123; int n = arr.length; MaxHeap&lt;Comparable&gt; maxHeap = new MaxHeap&lt;Comparable&gt;(n); for( int i = 0 ; i &lt; n ; i ++ ) maxHeap.insert(arr[i]); for( int i = n-1 ; i &gt;= 0 ; i -- ) arr[i] = maxHeap.extractMax(); &#125; // 只通过shiftDown操作进行排序 public static void sort2(Comparable[] arr)&#123; int n = arr.length; // 注意，此时我们的堆是从0开始索引的 // 从(最后一个元素的索引-1)/2开始 // 最后一个元素的索引 = n-1 for( int i = (n-1-1)/2 ; i &gt;= 0 ; i -- ) shiftDown2(arr, n, i); for( int i = n-1; i &gt; 0 ; i-- )&#123; // 这个的目的是让序列从小到大排序 swap( arr, 0, i); shiftDown2(arr, i, 0); &#125; &#125; // 交换堆中索引为i和j的两个元素 private static void swap(Object[] arr, int i, int j)&#123; Object t = arr[i]; arr[i] = arr[j]; arr[j] = t; &#125; // 原始的shiftDown过程 private static void shiftDown(Comparable[] arr, int n, int k)&#123; while( 2*k+1 &lt; n )&#123; int j = 2*k+1; if( j+1 &lt; n &amp;&amp; arr[j+1].compareTo(arr[j]) &gt; 0 ) j += 1; if( arr[k].compareTo(arr[j]) &gt;= 0 )break; swap( arr, k, j); k = j; &#125; &#125; // 优化的shiftDown过程, 使用赋值的方式取代不断的swap, // 该优化思想和我们之前对插入排序进行优化的思路是一致的 private static void shiftDown2(Comparable[] arr, int n, int k)&#123; Comparable e = arr[k]; while( 2*k+1 &lt; n )&#123; int j = 2*k+1; if( j+1 &lt; n &amp;&amp; arr[j+1].compareTo(arr[j]) &gt; 0 ) j += 1; if( e.compareTo(arr[j]) &gt;= 0 ) break; arr[k] = arr[j]; k = j; &#125; arr[k] = e; &#125; // 测试 HeapSort public static void main(String[] args) &#123; Integer[] arr = &#123;10, 91, 8, 7, 6, 5, 4, 3, 2, 1&#125;; HeapSort.sort2(arr); PrintHelper.printArray(arr); &#125;&#125; 6. 堆排序的应用——Top K问题例如，有1亿个浮点数，如何找出其中最大的10000个？ 计数排序算法描述1.计数排序是一种非常快捷的稳定性强的排序方法，时间复杂度O(n+k),其中n为要排序的数的个数，k为要排序的数的组大值。计数排序对一定量的整数排序时候的速度非常快，一般快于其他排序算法。但计数排序局限性比较大，只限于对整数进行排序。计数排序是消耗空间发杂度来获取快捷的排序方法，其空间发展度为O（K）同理K为要排序的最大值。 2.计数排序的基本思想为一组数在排序之前先统计这组数中其他数小于这个数的个数，则可以确定这个数的位置。例如要排序的数为 7 4 2 1 5 3 1 5；则比7小的有7个数，所有7应该在排序好的数列的第八位，同理3在第四位，对于重复的数字，1在1位和2位（暂且认为第一个1比第二个1小），5和1一样位于6位和7位。 3.计数排序的实现办法： 首先需要三个数组，第一个数组记录A要排序的数列大小为n，第二个数组B要记录比某个数小的其他数字的个数所以第二个数组的大小应当为K（数列中最大数的大小），第三个数组C为记录排序好了的数列的数组，大小应当为n。 接着需要确定数组最大值并确定B数组的大小。并对每个数由小到大的记录数列中每个数的出现次数。因为是有小到大通过出现次数可以通过前面的所有数的出现次数来确定比这个数小的数的个数，从而确定其位置。 对于重复的数，每排好一个数则对其位置数进行减减操作，以此对完成其余相同的数字进行排位。 代码实现 123456789101112131415161718192021222324252627282930313233343536373839404142#include&lt;iostream&gt;#include&lt;stdlib.h&gt;using namespace std;int main()&#123; int n; cin &gt;&gt; n; int *a = new int[n]; int *c = new int[n]; memset(a, 0, n*sizeof(int)); memset(c, 0, n*sizeof(int)); int max = 0; for (int i = 0; i &lt; n; i++) &#123; cin &gt;&gt; a[i]; max = a[i]&gt;max ? a[i] : max; &#125; int *b = new int[max+1]; memset(b, 0, (max+1)*sizeof(int)); for (int i = 0; i &lt; n; i++) &#123; b[a[i]]++; &#125; for (int i = 1; i &lt; max + 1; i++) &#123; b[i] = b[i] + b[i - 1]; &#125; for (int i = 0; i &lt; n; i++) &#123; b[a[i]]--; c[b[a[i]]] = a[i]; &#125; for (int i = 0; i &lt; n; i++) cout &lt;&lt; c[i] &lt;&lt; endl; delete[]a; delete[]b; delete[]c; return 0;&#125; 运行结果: 102 1 3 4 2 5 6 1 8 1111223456811请按任意键继续. . . 这就是传说中的时间复杂度只有O（n）的排序算法； 排序算法总结 平均时间复杂度 原地排序 额外空间 稳定排序 插入排序 O(n^2) √ O(1) √ 归并排序 O(nlogn) × O(n) √ 快速排序 O(nlogn) √ O(logn) × 堆排序 O(nlogn) √ O(1) × 稳定排序：对于相等的元素，在排序后，原来靠前的元素依然靠前。相等元素的相对位置没有发生变化。 123456// 可以通过⾃自定义⽐比较函数，让排序算法不不存在稳定性的问题。bool operator&lt;(const Student&amp; otherStudent)&#123; return score != otherStudent.score ? score &gt; otherStudent.score : name &lt; otherStudent.name;&#125; 十大经典排序算法（动图演示）","tags":[{"name":"面试题","slug":"面试题","permalink":"https://imnice.github.io/tags/面试题/"},{"name":"算法","slug":"算法","permalink":"https://imnice.github.io/tags/算法/"}]}]